{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the libraries for video classification\n",
    "import torch, os, cv2\n",
    "from torchvision.models.video.resnet import BasicBlock, Conv3DSimple\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from lipreading.model import Lipreading\n",
    "from lipreading.optim_utils import CosineScheduler\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Initialize the seed and the device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting the seed for reproducibility\n",
    "seed = 0\n",
    "def reset_seed():\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "# Setting the device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Dataset preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1. List of Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ٱ': 1, 'يْ': 2, 'يّْ': 3, 'يِّ': 4, 'يُّ': 5, 'يَّ': 6, 'يٌّ': 7, 'يِ': 8, 'يُ': 9, 'يَ': 10, 'يٌ': 11, 'ي': 12, 'ى': 13, 'وْ': 14, 'وِّ': 15, 'وُّ': 16, 'وَّ': 17, 'وِ': 18, 'وُ': 19, 'وَ': 20, 'وً': 21, 'و': 22, 'هْ': 23, 'هُّ': 24, 'هِ': 25, 'هُ': 26, 'هَ': 27, 'نۢ': 28, 'نْ': 29, 'نِّ': 30, 'نُّ': 31, 'نَّ': 32, 'نِ': 33, 'نُ': 34, 'نَ': 35, 'ن': 36, 'مْ': 37, 'مّْ': 38, 'مِّ': 39, 'مُّ': 40, 'مَّ': 41, 'مِ': 42, 'مُ': 43, 'مَ': 44, 'مٍ': 45, 'مٌ': 46, 'مً': 47, 'لْ': 48, 'لّْ': 49, 'لِّ': 50, 'لُّ': 51, 'لَّ': 52, 'لِ': 53, 'لُ': 54, 'لَ': 55, 'لٍ': 56, 'لٌ': 57, 'لً': 58, 'ل': 59, 'كْ': 60, 'كِّ': 61, 'كَّ': 62, 'كِ': 63, 'كُ': 64, 'كَ': 65, 'ك': 66, 'قْ': 67, 'قَّ': 68, 'قِ': 69, 'قُ': 70, 'قَ': 71, 'قٍ': 72, 'قً': 73, 'ق': 74, 'فْ': 75, 'فِّ': 76, 'فَّ': 77, 'فِ': 78, 'فُ': 79, 'فَ': 80, 'غْ': 81, 'غِ': 82, 'غَ': 83, 'عْ': 84, 'عَّ': 85, 'عِ': 86, 'عُ': 87, 'عَ': 88, 'عٍ': 89, 'ظْ': 90, 'ظِّ': 91, 'ظَّ': 92, 'ظِ': 93, 'ظُ': 94, 'ظَ': 95, 'طْ': 96, 'طِّ': 97, 'طَّ': 98, 'طِ': 99, 'طُ': 100, 'طَ': 101, 'ط': 102, 'ضْ': 103, 'ضِّ': 104, 'ضُّ': 105, 'ضَّ': 106, 'ضِ': 107, 'ضُ': 108, 'ضَ': 109, 'ضً': 110, 'صْ': 111, 'صّْ': 112, 'صِّ': 113, 'صُّ': 114, 'صَّ': 115, 'صِ': 116, 'صُ': 117, 'صَ': 118, 'صٍ': 119, 'صً': 120, 'شْ': 121, 'شِّ': 122, 'شُّ': 123, 'شَّ': 124, 'شِ': 125, 'شُ': 126, 'شَ': 127, 'ش': 128, 'سْ': 129, 'سّْ': 130, 'سِّ': 131, 'سُّ': 132, 'سَّ': 133, 'سِ': 134, 'سُ': 135, 'سَ': 136, 'سٍ': 137, 'زْ': 138, 'زَّ': 139, 'زِ': 140, 'زُ': 141, 'زَ': 142, 'رْ': 143, 'رِّ': 144, 'رُّ': 145, 'رَّ': 146, 'رِ': 147, 'رُ': 148, 'رَ': 149, 'رٍ': 150, 'رٌ': 151, 'رً': 152, 'ذْ': 153, 'ذَّ': 154, 'ذِ': 155, 'ذُ': 156, 'ذَ': 157, 'دْ': 158, 'دِّ': 159, 'دُّ': 160, 'دَّ': 161, 'دًّ': 162, 'دِ': 163, 'دُ': 164, 'دَ': 165, 'دٍ': 166, 'دٌ': 167, 'دً': 168, 'خْ': 169, 'خِ': 170, 'خُ': 171, 'خَ': 172, 'حْ': 173, 'حَّ': 174, 'حِ': 175, 'حُ': 176, 'حَ': 177, 'ح': 178, 'جْ': 179, 'جِّ': 180, 'جُّ': 181, 'جَّ': 182, 'جِ': 183, 'جُ': 184, 'جَ': 185, 'ثْ': 186, 'ثِّ': 187, 'ثُّ': 188, 'ثَّ': 189, 'ثِ': 190, 'ثُ': 191, 'ثَ': 192, 'تْ': 193, 'تِّ': 194, 'تُّ': 195, 'تَّ': 196, 'تِ': 197, 'تُ': 198, 'تَ': 199, 'تٍ': 200, 'تٌ': 201, 'ةْ': 202, 'ةِ': 203, 'ةُ': 204, 'ةَ': 205, 'ةٍ': 206, 'ةٌ': 207, 'ةً': 208, 'ة': 209, 'بْ': 210, 'بِّ': 211, 'بَّ': 212, 'بِ': 213, 'بُ': 214, 'بَ': 215, 'بٍ': 216, 'بً': 217, 'ب': 218, 'ا': 219, 'ئْ': 220, 'ئِ': 221, 'ئَ': 222, 'ئً': 223, 'إِ': 224, 'إ': 225, 'ؤْ': 226, 'ؤُ': 227, 'ؤَ': 228, 'ؤ': 229, 'أْ': 230, 'أُ': 231, 'أَ': 232, 'آ': 233, 'ءْ': 234, 'ءِ': 235, 'ءَ': 236, 'ءً': 237}\n"
     ]
    }
   ],
   "source": [
    "def extract_label(file):\n",
    "    label = []\n",
    "    diacritics = {\n",
    "        '\\u064B',  # Fathatan\n",
    "        '\\u064C',  # Dammatan\n",
    "        '\\u064D',  # Kasratan\n",
    "        '\\u064E',  # Fatha\n",
    "        '\\u064F',  # Damma\n",
    "        '\\u0650',  # Kasra\n",
    "        '\\u0651',  # Shadda\n",
    "        '\\u0652',  # Sukun\n",
    "        '\\u06E2',  # Small High meem\n",
    "    }\n",
    "\n",
    "    sentence = pd.read_csv(file)\n",
    "    for word in sentence.word:\n",
    "        for char in word:\n",
    "            if char not in diacritics:\n",
    "                label.append(char)\n",
    "            else:\n",
    "                label[-1] += char\n",
    "\n",
    "    return label\n",
    "\n",
    "classes = set()\n",
    "for i in os.listdir('Dataset/Csv (with Diacritics)'):\n",
    "    file = 'Dataset/Csv (with Diacritics)/' + i\n",
    "    label = extract_label(file)\n",
    "    classes.update(label)\n",
    "\n",
    "mapped_classes = {}\n",
    "for i, c in enumerate(sorted(classes, reverse=True), 1):\n",
    "    mapped_classes[c] = i\n",
    "\n",
    "print(mapped_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2. Video Dataset Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the video dataset class\n",
    "class VideoDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, video_paths, label_paths, transform=None):\n",
    "        self.video_paths = video_paths\n",
    "        self.label_paths = label_paths\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.video_paths)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        video_path = self.video_paths[index]\n",
    "        label_path = self.label_paths[index]\n",
    "        frames = self.load_frames(video_path=video_path)\n",
    "        label = list(map(lambda x: mapped_classes[x], extract_label(label_path)))\n",
    "        return np.array(frames), np.array(label)\n",
    "    \n",
    "    def load_frames(self, video_path):\n",
    "        frames = []\n",
    "        video = cv2.VideoCapture(video_path)\n",
    "        total_frames = int(video.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "        for i in range(total_frames):\n",
    "            video.set(cv2.CAP_PROP_POS_FRAMES, i)\n",
    "            ret, frame = video.read()\n",
    "            if ret:\n",
    "                frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "                frame_pil = Image.fromarray(frame)\n",
    "                frames.append(frame_pil)\n",
    "\n",
    "        if self.transform is not None:\n",
    "            frames = [self.transform(frame) for frame in frames] \n",
    "        frames = torch.stack(frames).permute(1, 0, 2, 3)\n",
    "        return frames\n",
    "\n",
    "# Defining the video transform\n",
    "transforms = transforms.Compose([\n",
    "    transforms.Resize((128, 128)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=0.421, std=0.165),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2. Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "videos_dir = \"Dataset/Video\"\n",
    "labels_dir = \"Dataset/Csv (with Diacritics)\"\n",
    "videos, labels = [], []\n",
    "file_names = [file_name[:-4] for file_name in os.listdir(videos_dir)]\n",
    "for file_name in file_names:\n",
    "    videos.append(os.path.join(videos_dir, file_name + \".mp4\"))\n",
    "    labels.append(os.path.join(labels_dir, file_name + \".csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3. Split the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into training, validation, test sets\n",
    "X_temp, X_test, y_temp, y_test = train_test_split(videos, labels, test_size=0.10, random_state=seed)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_temp, y_temp, test_size=0.11, random_state=seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4. DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_packed_collate(batch):\n",
    "    \"\"\"Pads data and labels with different lengths in the same batch\n",
    "    \"\"\"\n",
    "    data_list, lengths, labels_list, label_lengths = zip(*[(a, a.shape[1], b, b.shape[0]) for (a, b) in sorted(batch, key=lambda x: x[0].shape[1], reverse=True)])\n",
    "    c, max_len, h, w = data_list[0].shape  # since it is sorted, the longest video is the first one\n",
    "    data_np = np.zeros((len(data_list), c, max_len, h, w))\n",
    "    \n",
    "    # Only copy up to the actual sequence length\n",
    "    for idx in range(len(data_np)):\n",
    "        data_np[idx, :, :lengths[idx], :, :] = data_list[idx][:, :lengths[idx], :, :]\n",
    "    data = torch.FloatTensor(data_np)\n",
    "    \n",
    "    # Flatten labels for CTC loss\n",
    "    labels_flat = []\n",
    "    for label_seq in labels_list:\n",
    "        labels_flat.extend(label_seq)\n",
    "    labels_flat = torch.LongTensor(labels_flat)\n",
    "    \n",
    "    # Convert lengths to tensor\n",
    "    lengths = torch.LongTensor(lengths)\n",
    "    label_lengths = torch.LongTensor(label_lengths)\n",
    "    return data, lengths, labels_flat, label_lengths\n",
    "\n",
    "\n",
    "# Defining the video dataloaders (train, validation, test)\n",
    "train_dataset = VideoDataset(X_train, y_train, transform=transforms)\n",
    "val_dataset = VideoDataset(X_val, y_val, transform=transforms)\n",
    "test_dataset = VideoDataset(X_test, y_test, transform=transforms)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, pin_memory=True, collate_fn=pad_packed_collate)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, pin_memory=True, collate_fn=pad_packed_collate)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, pin_memory=True, collate_fn=pad_packed_collate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lipreading(\n",
      "  (trunk): ResNet(\n",
      "    (layer1): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): PReLU(num_parameters=64)\n",
      "        (relu2): PReLU(num_parameters=64)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): PReLU(num_parameters=64)\n",
      "        (relu2): PReLU(num_parameters=64)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (layer2): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): PReLU(num_parameters=128)\n",
      "        (relu2): PReLU(num_parameters=128)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): PReLU(num_parameters=128)\n",
      "        (relu2): PReLU(num_parameters=128)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (layer3): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): PReLU(num_parameters=256)\n",
      "        (relu2): PReLU(num_parameters=256)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): PReLU(num_parameters=256)\n",
      "        (relu2): PReLU(num_parameters=256)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (layer4): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): PReLU(num_parameters=512)\n",
      "        (relu2): PReLU(num_parameters=512)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): PReLU(num_parameters=512)\n",
      "        (relu2): PReLU(num_parameters=512)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "  )\n",
      "  (frontend3D): Sequential(\n",
      "    (0): Conv3d(1, 64, kernel_size=(5, 7, 7), stride=(1, 2, 2), padding=(2, 3, 3), bias=False)\n",
      "    (1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): PReLU(num_parameters=64)\n",
      "    (3): MaxPool3d(kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (tcn): DenseTCN(\n",
      "    (tcn_trunk): DenseTemporalConvNet(\n",
      "      (features): Sequential(\n",
      "        (transition0): _Transition(\n",
      "          (conv): Conv1d(512, 512, kernel_size=(1,), stride=(1,), bias=False)\n",
      "          (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (prelu): PReLU(num_parameters=512)\n",
      "        )\n",
      "        (denseblock1): _DenseBlock(\n",
      "          (denselayer1): _ConvBatchChompRelu(\n",
      "            (cbcr0_se_0): SELayer(\n",
      "              (avg_pool): AdaptiveAvgPool1d(output_size=1)\n",
      "              (fc): Sequential(\n",
      "                (0): Linear(in_features=512, out_features=32, bias=False)\n",
      "                (1): Swish()\n",
      "                (2): Linear(in_features=32, out_features=512, bias=False)\n",
      "                (3): Sigmoid()\n",
      "              )\n",
      "            )\n",
      "            (cbcr0_0): TemporalConvLayer(\n",
      "              (net): Sequential(\n",
      "                (0): Conv1d(512, 128, kernel_size=(3,), stride=(1,), padding=(2,))\n",
      "                (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (2): Chomp1d()\n",
      "                (3): PReLU(num_parameters=128)\n",
      "              )\n",
      "            )\n",
      "            (cbcr0_se_1): SELayer(\n",
      "              (avg_pool): AdaptiveAvgPool1d(output_size=1)\n",
      "              (fc): Sequential(\n",
      "                (0): Linear(in_features=512, out_features=32, bias=False)\n",
      "                (1): Swish()\n",
      "                (2): Linear(in_features=32, out_features=512, bias=False)\n",
      "                (3): Sigmoid()\n",
      "              )\n",
      "            )\n",
      "            (cbcr0_1): TemporalConvLayer(\n",
      "              (net): Sequential(\n",
      "                (0): Conv1d(512, 128, kernel_size=(5,), stride=(1,), padding=(4,))\n",
      "                (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (2): Chomp1d()\n",
      "                (3): PReLU(num_parameters=128)\n",
      "              )\n",
      "            )\n",
      "            (cbcr0_se_2): SELayer(\n",
      "              (avg_pool): AdaptiveAvgPool1d(output_size=1)\n",
      "              (fc): Sequential(\n",
      "                (0): Linear(in_features=512, out_features=32, bias=False)\n",
      "                (1): Swish()\n",
      "                (2): Linear(in_features=32, out_features=512, bias=False)\n",
      "                (3): Sigmoid()\n",
      "              )\n",
      "            )\n",
      "            (cbcr0_2): TemporalConvLayer(\n",
      "              (net): Sequential(\n",
      "                (0): Conv1d(512, 128, kernel_size=(7,), stride=(1,), padding=(6,))\n",
      "                (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (2): Chomp1d()\n",
      "                (3): PReLU(num_parameters=128)\n",
      "              )\n",
      "            )\n",
      "            (dropout0): Dropout(p=0.2, inplace=False)\n",
      "            (cbcr1_0): TemporalConvLayer(\n",
      "              (net): Sequential(\n",
      "                (0): Conv1d(384, 128, kernel_size=(3,), stride=(1,), padding=(2,))\n",
      "                (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (2): Chomp1d()\n",
      "                (3): PReLU(num_parameters=128)\n",
      "              )\n",
      "            )\n",
      "            (cbcr1_1): TemporalConvLayer(\n",
      "              (net): Sequential(\n",
      "                (0): Conv1d(384, 128, kernel_size=(5,), stride=(1,), padding=(4,))\n",
      "                (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (2): Chomp1d()\n",
      "                (3): PReLU(num_parameters=128)\n",
      "              )\n",
      "            )\n",
      "            (cbcr1_2): TemporalConvLayer(\n",
      "              (net): Sequential(\n",
      "                (0): Conv1d(384, 128, kernel_size=(7,), stride=(1,), padding=(6,))\n",
      "                (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (2): Chomp1d()\n",
      "                (3): PReLU(num_parameters=128)\n",
      "              )\n",
      "            )\n",
      "            (dropout1): Dropout(p=0.2, inplace=False)\n",
      "            (downsample): Conv1d(512, 384, kernel_size=(1,), stride=(1,))\n",
      "            (relu_final): PReLU(num_parameters=384)\n",
      "          )\n",
      "          (denselayer2): _ConvBatchChompRelu(\n",
      "            (cbcr0_se_0): SELayer(\n",
      "              (avg_pool): AdaptiveAvgPool1d(output_size=1)\n",
      "              (fc): Sequential(\n",
      "                (0): Linear(in_features=896, out_features=56, bias=False)\n",
      "                (1): Swish()\n",
      "                (2): Linear(in_features=56, out_features=896, bias=False)\n",
      "                (3): Sigmoid()\n",
      "              )\n",
      "            )\n",
      "            (cbcr0_0): TemporalConvLayer(\n",
      "              (net): Sequential(\n",
      "                (0): Conv1d(896, 128, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(2,))\n",
      "                (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (2): Chomp1d()\n",
      "                (3): PReLU(num_parameters=128)\n",
      "              )\n",
      "            )\n",
      "            (cbcr0_se_1): SELayer(\n",
      "              (avg_pool): AdaptiveAvgPool1d(output_size=1)\n",
      "              (fc): Sequential(\n",
      "                (0): Linear(in_features=896, out_features=56, bias=False)\n",
      "                (1): Swish()\n",
      "                (2): Linear(in_features=56, out_features=896, bias=False)\n",
      "                (3): Sigmoid()\n",
      "              )\n",
      "            )\n",
      "            (cbcr0_1): TemporalConvLayer(\n",
      "              (net): Sequential(\n",
      "                (0): Conv1d(896, 128, kernel_size=(5,), stride=(1,), padding=(8,), dilation=(2,))\n",
      "                (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (2): Chomp1d()\n",
      "                (3): PReLU(num_parameters=128)\n",
      "              )\n",
      "            )\n",
      "            (cbcr0_se_2): SELayer(\n",
      "              (avg_pool): AdaptiveAvgPool1d(output_size=1)\n",
      "              (fc): Sequential(\n",
      "                (0): Linear(in_features=896, out_features=56, bias=False)\n",
      "                (1): Swish()\n",
      "                (2): Linear(in_features=56, out_features=896, bias=False)\n",
      "                (3): Sigmoid()\n",
      "              )\n",
      "            )\n",
      "            (cbcr0_2): TemporalConvLayer(\n",
      "              (net): Sequential(\n",
      "                (0): Conv1d(896, 128, kernel_size=(7,), stride=(1,), padding=(12,), dilation=(2,))\n",
      "                (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (2): Chomp1d()\n",
      "                (3): PReLU(num_parameters=128)\n",
      "              )\n",
      "            )\n",
      "            (dropout0): Dropout(p=0.2, inplace=False)\n",
      "            (cbcr1_0): TemporalConvLayer(\n",
      "              (net): Sequential(\n",
      "                (0): Conv1d(384, 128, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(2,))\n",
      "                (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (2): Chomp1d()\n",
      "                (3): PReLU(num_parameters=128)\n",
      "              )\n",
      "            )\n",
      "            (cbcr1_1): TemporalConvLayer(\n",
      "              (net): Sequential(\n",
      "                (0): Conv1d(384, 128, kernel_size=(5,), stride=(1,), padding=(8,), dilation=(2,))\n",
      "                (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (2): Chomp1d()\n",
      "                (3): PReLU(num_parameters=128)\n",
      "              )\n",
      "            )\n",
      "            (cbcr1_2): TemporalConvLayer(\n",
      "              (net): Sequential(\n",
      "                (0): Conv1d(384, 128, kernel_size=(7,), stride=(1,), padding=(12,), dilation=(2,))\n",
      "                (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (2): Chomp1d()\n",
      "                (3): PReLU(num_parameters=128)\n",
      "              )\n",
      "            )\n",
      "            (dropout1): Dropout(p=0.2, inplace=False)\n",
      "            (downsample): Conv1d(896, 384, kernel_size=(1,), stride=(1,))\n",
      "            (relu_final): PReLU(num_parameters=384)\n",
      "          )\n",
      "          (denselayer3): _ConvBatchChompRelu(\n",
      "            (cbcr0_se_0): SELayer(\n",
      "              (avg_pool): AdaptiveAvgPool1d(output_size=1)\n",
      "              (fc): Sequential(\n",
      "                (0): Linear(in_features=1280, out_features=80, bias=False)\n",
      "                (1): Swish()\n",
      "                (2): Linear(in_features=80, out_features=1280, bias=False)\n",
      "                (3): Sigmoid()\n",
      "              )\n",
      "            )\n",
      "            (cbcr0_0): TemporalConvLayer(\n",
      "              (net): Sequential(\n",
      "                (0): Conv1d(1280, 128, kernel_size=(3,), stride=(1,), padding=(10,), dilation=(5,))\n",
      "                (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (2): Chomp1d()\n",
      "                (3): PReLU(num_parameters=128)\n",
      "              )\n",
      "            )\n",
      "            (cbcr0_se_1): SELayer(\n",
      "              (avg_pool): AdaptiveAvgPool1d(output_size=1)\n",
      "              (fc): Sequential(\n",
      "                (0): Linear(in_features=1280, out_features=80, bias=False)\n",
      "                (1): Swish()\n",
      "                (2): Linear(in_features=80, out_features=1280, bias=False)\n",
      "                (3): Sigmoid()\n",
      "              )\n",
      "            )\n",
      "            (cbcr0_1): TemporalConvLayer(\n",
      "              (net): Sequential(\n",
      "                (0): Conv1d(1280, 128, kernel_size=(5,), stride=(1,), padding=(20,), dilation=(5,))\n",
      "                (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (2): Chomp1d()\n",
      "                (3): PReLU(num_parameters=128)\n",
      "              )\n",
      "            )\n",
      "            (cbcr0_se_2): SELayer(\n",
      "              (avg_pool): AdaptiveAvgPool1d(output_size=1)\n",
      "              (fc): Sequential(\n",
      "                (0): Linear(in_features=1280, out_features=80, bias=False)\n",
      "                (1): Swish()\n",
      "                (2): Linear(in_features=80, out_features=1280, bias=False)\n",
      "                (3): Sigmoid()\n",
      "              )\n",
      "            )\n",
      "            (cbcr0_2): TemporalConvLayer(\n",
      "              (net): Sequential(\n",
      "                (0): Conv1d(1280, 128, kernel_size=(7,), stride=(1,), padding=(30,), dilation=(5,))\n",
      "                (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (2): Chomp1d()\n",
      "                (3): PReLU(num_parameters=128)\n",
      "              )\n",
      "            )\n",
      "            (dropout0): Dropout(p=0.2, inplace=False)\n",
      "            (cbcr1_0): TemporalConvLayer(\n",
      "              (net): Sequential(\n",
      "                (0): Conv1d(384, 128, kernel_size=(3,), stride=(1,), padding=(10,), dilation=(5,))\n",
      "                (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (2): Chomp1d()\n",
      "                (3): PReLU(num_parameters=128)\n",
      "              )\n",
      "            )\n",
      "            (cbcr1_1): TemporalConvLayer(\n",
      "              (net): Sequential(\n",
      "                (0): Conv1d(384, 128, kernel_size=(5,), stride=(1,), padding=(20,), dilation=(5,))\n",
      "                (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (2): Chomp1d()\n",
      "                (3): PReLU(num_parameters=128)\n",
      "              )\n",
      "            )\n",
      "            (cbcr1_2): TemporalConvLayer(\n",
      "              (net): Sequential(\n",
      "                (0): Conv1d(384, 128, kernel_size=(7,), stride=(1,), padding=(30,), dilation=(5,))\n",
      "                (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (2): Chomp1d()\n",
      "                (3): PReLU(num_parameters=128)\n",
      "              )\n",
      "            )\n",
      "            (dropout1): Dropout(p=0.2, inplace=False)\n",
      "            (downsample): Conv1d(1280, 384, kernel_size=(1,), stride=(1,))\n",
      "            (relu_final): PReLU(num_parameters=384)\n",
      "          )\n",
      "        )\n",
      "        (transition1): _Transition(\n",
      "          (conv): Conv1d(1664, 512, kernel_size=(1,), stride=(1,), bias=False)\n",
      "          (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (prelu): PReLU(num_parameters=512)\n",
      "        )\n",
      "        (denseblock2): _DenseBlock(\n",
      "          (denselayer1): _ConvBatchChompRelu(\n",
      "            (cbcr0_se_0): SELayer(\n",
      "              (avg_pool): AdaptiveAvgPool1d(output_size=1)\n",
      "              (fc): Sequential(\n",
      "                (0): Linear(in_features=512, out_features=32, bias=False)\n",
      "                (1): Swish()\n",
      "                (2): Linear(in_features=32, out_features=512, bias=False)\n",
      "                (3): Sigmoid()\n",
      "              )\n",
      "            )\n",
      "            (cbcr0_0): TemporalConvLayer(\n",
      "              (net): Sequential(\n",
      "                (0): Conv1d(512, 128, kernel_size=(3,), stride=(1,), padding=(2,))\n",
      "                (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (2): Chomp1d()\n",
      "                (3): PReLU(num_parameters=128)\n",
      "              )\n",
      "            )\n",
      "            (cbcr0_se_1): SELayer(\n",
      "              (avg_pool): AdaptiveAvgPool1d(output_size=1)\n",
      "              (fc): Sequential(\n",
      "                (0): Linear(in_features=512, out_features=32, bias=False)\n",
      "                (1): Swish()\n",
      "                (2): Linear(in_features=32, out_features=512, bias=False)\n",
      "                (3): Sigmoid()\n",
      "              )\n",
      "            )\n",
      "            (cbcr0_1): TemporalConvLayer(\n",
      "              (net): Sequential(\n",
      "                (0): Conv1d(512, 128, kernel_size=(5,), stride=(1,), padding=(4,))\n",
      "                (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (2): Chomp1d()\n",
      "                (3): PReLU(num_parameters=128)\n",
      "              )\n",
      "            )\n",
      "            (cbcr0_se_2): SELayer(\n",
      "              (avg_pool): AdaptiveAvgPool1d(output_size=1)\n",
      "              (fc): Sequential(\n",
      "                (0): Linear(in_features=512, out_features=32, bias=False)\n",
      "                (1): Swish()\n",
      "                (2): Linear(in_features=32, out_features=512, bias=False)\n",
      "                (3): Sigmoid()\n",
      "              )\n",
      "            )\n",
      "            (cbcr0_2): TemporalConvLayer(\n",
      "              (net): Sequential(\n",
      "                (0): Conv1d(512, 128, kernel_size=(7,), stride=(1,), padding=(6,))\n",
      "                (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (2): Chomp1d()\n",
      "                (3): PReLU(num_parameters=128)\n",
      "              )\n",
      "            )\n",
      "            (dropout0): Dropout(p=0.2, inplace=False)\n",
      "            (cbcr1_0): TemporalConvLayer(\n",
      "              (net): Sequential(\n",
      "                (0): Conv1d(384, 128, kernel_size=(3,), stride=(1,), padding=(2,))\n",
      "                (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (2): Chomp1d()\n",
      "                (3): PReLU(num_parameters=128)\n",
      "              )\n",
      "            )\n",
      "            (cbcr1_1): TemporalConvLayer(\n",
      "              (net): Sequential(\n",
      "                (0): Conv1d(384, 128, kernel_size=(5,), stride=(1,), padding=(4,))\n",
      "                (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (2): Chomp1d()\n",
      "                (3): PReLU(num_parameters=128)\n",
      "              )\n",
      "            )\n",
      "            (cbcr1_2): TemporalConvLayer(\n",
      "              (net): Sequential(\n",
      "                (0): Conv1d(384, 128, kernel_size=(7,), stride=(1,), padding=(6,))\n",
      "                (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (2): Chomp1d()\n",
      "                (3): PReLU(num_parameters=128)\n",
      "              )\n",
      "            )\n",
      "            (dropout1): Dropout(p=0.2, inplace=False)\n",
      "            (downsample): Conv1d(512, 384, kernel_size=(1,), stride=(1,))\n",
      "            (relu_final): PReLU(num_parameters=384)\n",
      "          )\n",
      "          (denselayer2): _ConvBatchChompRelu(\n",
      "            (cbcr0_se_0): SELayer(\n",
      "              (avg_pool): AdaptiveAvgPool1d(output_size=1)\n",
      "              (fc): Sequential(\n",
      "                (0): Linear(in_features=896, out_features=56, bias=False)\n",
      "                (1): Swish()\n",
      "                (2): Linear(in_features=56, out_features=896, bias=False)\n",
      "                (3): Sigmoid()\n",
      "              )\n",
      "            )\n",
      "            (cbcr0_0): TemporalConvLayer(\n",
      "              (net): Sequential(\n",
      "                (0): Conv1d(896, 128, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(2,))\n",
      "                (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (2): Chomp1d()\n",
      "                (3): PReLU(num_parameters=128)\n",
      "              )\n",
      "            )\n",
      "            (cbcr0_se_1): SELayer(\n",
      "              (avg_pool): AdaptiveAvgPool1d(output_size=1)\n",
      "              (fc): Sequential(\n",
      "                (0): Linear(in_features=896, out_features=56, bias=False)\n",
      "                (1): Swish()\n",
      "                (2): Linear(in_features=56, out_features=896, bias=False)\n",
      "                (3): Sigmoid()\n",
      "              )\n",
      "            )\n",
      "            (cbcr0_1): TemporalConvLayer(\n",
      "              (net): Sequential(\n",
      "                (0): Conv1d(896, 128, kernel_size=(5,), stride=(1,), padding=(8,), dilation=(2,))\n",
      "                (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (2): Chomp1d()\n",
      "                (3): PReLU(num_parameters=128)\n",
      "              )\n",
      "            )\n",
      "            (cbcr0_se_2): SELayer(\n",
      "              (avg_pool): AdaptiveAvgPool1d(output_size=1)\n",
      "              (fc): Sequential(\n",
      "                (0): Linear(in_features=896, out_features=56, bias=False)\n",
      "                (1): Swish()\n",
      "                (2): Linear(in_features=56, out_features=896, bias=False)\n",
      "                (3): Sigmoid()\n",
      "              )\n",
      "            )\n",
      "            (cbcr0_2): TemporalConvLayer(\n",
      "              (net): Sequential(\n",
      "                (0): Conv1d(896, 128, kernel_size=(7,), stride=(1,), padding=(12,), dilation=(2,))\n",
      "                (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (2): Chomp1d()\n",
      "                (3): PReLU(num_parameters=128)\n",
      "              )\n",
      "            )\n",
      "            (dropout0): Dropout(p=0.2, inplace=False)\n",
      "            (cbcr1_0): TemporalConvLayer(\n",
      "              (net): Sequential(\n",
      "                (0): Conv1d(384, 128, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(2,))\n",
      "                (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (2): Chomp1d()\n",
      "                (3): PReLU(num_parameters=128)\n",
      "              )\n",
      "            )\n",
      "            (cbcr1_1): TemporalConvLayer(\n",
      "              (net): Sequential(\n",
      "                (0): Conv1d(384, 128, kernel_size=(5,), stride=(1,), padding=(8,), dilation=(2,))\n",
      "                (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (2): Chomp1d()\n",
      "                (3): PReLU(num_parameters=128)\n",
      "              )\n",
      "            )\n",
      "            (cbcr1_2): TemporalConvLayer(\n",
      "              (net): Sequential(\n",
      "                (0): Conv1d(384, 128, kernel_size=(7,), stride=(1,), padding=(12,), dilation=(2,))\n",
      "                (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (2): Chomp1d()\n",
      "                (3): PReLU(num_parameters=128)\n",
      "              )\n",
      "            )\n",
      "            (dropout1): Dropout(p=0.2, inplace=False)\n",
      "            (downsample): Conv1d(896, 384, kernel_size=(1,), stride=(1,))\n",
      "            (relu_final): PReLU(num_parameters=384)\n",
      "          )\n",
      "          (denselayer3): _ConvBatchChompRelu(\n",
      "            (cbcr0_se_0): SELayer(\n",
      "              (avg_pool): AdaptiveAvgPool1d(output_size=1)\n",
      "              (fc): Sequential(\n",
      "                (0): Linear(in_features=1280, out_features=80, bias=False)\n",
      "                (1): Swish()\n",
      "                (2): Linear(in_features=80, out_features=1280, bias=False)\n",
      "                (3): Sigmoid()\n",
      "              )\n",
      "            )\n",
      "            (cbcr0_0): TemporalConvLayer(\n",
      "              (net): Sequential(\n",
      "                (0): Conv1d(1280, 128, kernel_size=(3,), stride=(1,), padding=(10,), dilation=(5,))\n",
      "                (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (2): Chomp1d()\n",
      "                (3): PReLU(num_parameters=128)\n",
      "              )\n",
      "            )\n",
      "            (cbcr0_se_1): SELayer(\n",
      "              (avg_pool): AdaptiveAvgPool1d(output_size=1)\n",
      "              (fc): Sequential(\n",
      "                (0): Linear(in_features=1280, out_features=80, bias=False)\n",
      "                (1): Swish()\n",
      "                (2): Linear(in_features=80, out_features=1280, bias=False)\n",
      "                (3): Sigmoid()\n",
      "              )\n",
      "            )\n",
      "            (cbcr0_1): TemporalConvLayer(\n",
      "              (net): Sequential(\n",
      "                (0): Conv1d(1280, 128, kernel_size=(5,), stride=(1,), padding=(20,), dilation=(5,))\n",
      "                (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (2): Chomp1d()\n",
      "                (3): PReLU(num_parameters=128)\n",
      "              )\n",
      "            )\n",
      "            (cbcr0_se_2): SELayer(\n",
      "              (avg_pool): AdaptiveAvgPool1d(output_size=1)\n",
      "              (fc): Sequential(\n",
      "                (0): Linear(in_features=1280, out_features=80, bias=False)\n",
      "                (1): Swish()\n",
      "                (2): Linear(in_features=80, out_features=1280, bias=False)\n",
      "                (3): Sigmoid()\n",
      "              )\n",
      "            )\n",
      "            (cbcr0_2): TemporalConvLayer(\n",
      "              (net): Sequential(\n",
      "                (0): Conv1d(1280, 128, kernel_size=(7,), stride=(1,), padding=(30,), dilation=(5,))\n",
      "                (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (2): Chomp1d()\n",
      "                (3): PReLU(num_parameters=128)\n",
      "              )\n",
      "            )\n",
      "            (dropout0): Dropout(p=0.2, inplace=False)\n",
      "            (cbcr1_0): TemporalConvLayer(\n",
      "              (net): Sequential(\n",
      "                (0): Conv1d(384, 128, kernel_size=(3,), stride=(1,), padding=(10,), dilation=(5,))\n",
      "                (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (2): Chomp1d()\n",
      "                (3): PReLU(num_parameters=128)\n",
      "              )\n",
      "            )\n",
      "            (cbcr1_1): TemporalConvLayer(\n",
      "              (net): Sequential(\n",
      "                (0): Conv1d(384, 128, kernel_size=(5,), stride=(1,), padding=(20,), dilation=(5,))\n",
      "                (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (2): Chomp1d()\n",
      "                (3): PReLU(num_parameters=128)\n",
      "              )\n",
      "            )\n",
      "            (cbcr1_2): TemporalConvLayer(\n",
      "              (net): Sequential(\n",
      "                (0): Conv1d(384, 128, kernel_size=(7,), stride=(1,), padding=(30,), dilation=(5,))\n",
      "                (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (2): Chomp1d()\n",
      "                (3): PReLU(num_parameters=128)\n",
      "              )\n",
      "            )\n",
      "            (dropout1): Dropout(p=0.2, inplace=False)\n",
      "            (downsample): Conv1d(1280, 384, kernel_size=(1,), stride=(1,))\n",
      "            (relu_final): PReLU(num_parameters=384)\n",
      "          )\n",
      "        )\n",
      "        (transition2): _Transition(\n",
      "          (conv): Conv1d(1664, 512, kernel_size=(1,), stride=(1,), bias=False)\n",
      "          (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (prelu): PReLU(num_parameters=512)\n",
      "        )\n",
      "        (denseblock3): _DenseBlock(\n",
      "          (denselayer1): _ConvBatchChompRelu(\n",
      "            (cbcr0_se_0): SELayer(\n",
      "              (avg_pool): AdaptiveAvgPool1d(output_size=1)\n",
      "              (fc): Sequential(\n",
      "                (0): Linear(in_features=512, out_features=32, bias=False)\n",
      "                (1): Swish()\n",
      "                (2): Linear(in_features=32, out_features=512, bias=False)\n",
      "                (3): Sigmoid()\n",
      "              )\n",
      "            )\n",
      "            (cbcr0_0): TemporalConvLayer(\n",
      "              (net): Sequential(\n",
      "                (0): Conv1d(512, 128, kernel_size=(3,), stride=(1,), padding=(2,))\n",
      "                (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (2): Chomp1d()\n",
      "                (3): PReLU(num_parameters=128)\n",
      "              )\n",
      "            )\n",
      "            (cbcr0_se_1): SELayer(\n",
      "              (avg_pool): AdaptiveAvgPool1d(output_size=1)\n",
      "              (fc): Sequential(\n",
      "                (0): Linear(in_features=512, out_features=32, bias=False)\n",
      "                (1): Swish()\n",
      "                (2): Linear(in_features=32, out_features=512, bias=False)\n",
      "                (3): Sigmoid()\n",
      "              )\n",
      "            )\n",
      "            (cbcr0_1): TemporalConvLayer(\n",
      "              (net): Sequential(\n",
      "                (0): Conv1d(512, 128, kernel_size=(5,), stride=(1,), padding=(4,))\n",
      "                (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (2): Chomp1d()\n",
      "                (3): PReLU(num_parameters=128)\n",
      "              )\n",
      "            )\n",
      "            (cbcr0_se_2): SELayer(\n",
      "              (avg_pool): AdaptiveAvgPool1d(output_size=1)\n",
      "              (fc): Sequential(\n",
      "                (0): Linear(in_features=512, out_features=32, bias=False)\n",
      "                (1): Swish()\n",
      "                (2): Linear(in_features=32, out_features=512, bias=False)\n",
      "                (3): Sigmoid()\n",
      "              )\n",
      "            )\n",
      "            (cbcr0_2): TemporalConvLayer(\n",
      "              (net): Sequential(\n",
      "                (0): Conv1d(512, 128, kernel_size=(7,), stride=(1,), padding=(6,))\n",
      "                (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (2): Chomp1d()\n",
      "                (3): PReLU(num_parameters=128)\n",
      "              )\n",
      "            )\n",
      "            (dropout0): Dropout(p=0.2, inplace=False)\n",
      "            (cbcr1_0): TemporalConvLayer(\n",
      "              (net): Sequential(\n",
      "                (0): Conv1d(384, 128, kernel_size=(3,), stride=(1,), padding=(2,))\n",
      "                (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (2): Chomp1d()\n",
      "                (3): PReLU(num_parameters=128)\n",
      "              )\n",
      "            )\n",
      "            (cbcr1_1): TemporalConvLayer(\n",
      "              (net): Sequential(\n",
      "                (0): Conv1d(384, 128, kernel_size=(5,), stride=(1,), padding=(4,))\n",
      "                (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (2): Chomp1d()\n",
      "                (3): PReLU(num_parameters=128)\n",
      "              )\n",
      "            )\n",
      "            (cbcr1_2): TemporalConvLayer(\n",
      "              (net): Sequential(\n",
      "                (0): Conv1d(384, 128, kernel_size=(7,), stride=(1,), padding=(6,))\n",
      "                (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (2): Chomp1d()\n",
      "                (3): PReLU(num_parameters=128)\n",
      "              )\n",
      "            )\n",
      "            (dropout1): Dropout(p=0.2, inplace=False)\n",
      "            (downsample): Conv1d(512, 384, kernel_size=(1,), stride=(1,))\n",
      "            (relu_final): PReLU(num_parameters=384)\n",
      "          )\n",
      "          (denselayer2): _ConvBatchChompRelu(\n",
      "            (cbcr0_se_0): SELayer(\n",
      "              (avg_pool): AdaptiveAvgPool1d(output_size=1)\n",
      "              (fc): Sequential(\n",
      "                (0): Linear(in_features=896, out_features=56, bias=False)\n",
      "                (1): Swish()\n",
      "                (2): Linear(in_features=56, out_features=896, bias=False)\n",
      "                (3): Sigmoid()\n",
      "              )\n",
      "            )\n",
      "            (cbcr0_0): TemporalConvLayer(\n",
      "              (net): Sequential(\n",
      "                (0): Conv1d(896, 128, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(2,))\n",
      "                (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (2): Chomp1d()\n",
      "                (3): PReLU(num_parameters=128)\n",
      "              )\n",
      "            )\n",
      "            (cbcr0_se_1): SELayer(\n",
      "              (avg_pool): AdaptiveAvgPool1d(output_size=1)\n",
      "              (fc): Sequential(\n",
      "                (0): Linear(in_features=896, out_features=56, bias=False)\n",
      "                (1): Swish()\n",
      "                (2): Linear(in_features=56, out_features=896, bias=False)\n",
      "                (3): Sigmoid()\n",
      "              )\n",
      "            )\n",
      "            (cbcr0_1): TemporalConvLayer(\n",
      "              (net): Sequential(\n",
      "                (0): Conv1d(896, 128, kernel_size=(5,), stride=(1,), padding=(8,), dilation=(2,))\n",
      "                (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (2): Chomp1d()\n",
      "                (3): PReLU(num_parameters=128)\n",
      "              )\n",
      "            )\n",
      "            (cbcr0_se_2): SELayer(\n",
      "              (avg_pool): AdaptiveAvgPool1d(output_size=1)\n",
      "              (fc): Sequential(\n",
      "                (0): Linear(in_features=896, out_features=56, bias=False)\n",
      "                (1): Swish()\n",
      "                (2): Linear(in_features=56, out_features=896, bias=False)\n",
      "                (3): Sigmoid()\n",
      "              )\n",
      "            )\n",
      "            (cbcr0_2): TemporalConvLayer(\n",
      "              (net): Sequential(\n",
      "                (0): Conv1d(896, 128, kernel_size=(7,), stride=(1,), padding=(12,), dilation=(2,))\n",
      "                (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (2): Chomp1d()\n",
      "                (3): PReLU(num_parameters=128)\n",
      "              )\n",
      "            )\n",
      "            (dropout0): Dropout(p=0.2, inplace=False)\n",
      "            (cbcr1_0): TemporalConvLayer(\n",
      "              (net): Sequential(\n",
      "                (0): Conv1d(384, 128, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(2,))\n",
      "                (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (2): Chomp1d()\n",
      "                (3): PReLU(num_parameters=128)\n",
      "              )\n",
      "            )\n",
      "            (cbcr1_1): TemporalConvLayer(\n",
      "              (net): Sequential(\n",
      "                (0): Conv1d(384, 128, kernel_size=(5,), stride=(1,), padding=(8,), dilation=(2,))\n",
      "                (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (2): Chomp1d()\n",
      "                (3): PReLU(num_parameters=128)\n",
      "              )\n",
      "            )\n",
      "            (cbcr1_2): TemporalConvLayer(\n",
      "              (net): Sequential(\n",
      "                (0): Conv1d(384, 128, kernel_size=(7,), stride=(1,), padding=(12,), dilation=(2,))\n",
      "                (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (2): Chomp1d()\n",
      "                (3): PReLU(num_parameters=128)\n",
      "              )\n",
      "            )\n",
      "            (dropout1): Dropout(p=0.2, inplace=False)\n",
      "            (downsample): Conv1d(896, 384, kernel_size=(1,), stride=(1,))\n",
      "            (relu_final): PReLU(num_parameters=384)\n",
      "          )\n",
      "          (denselayer3): _ConvBatchChompRelu(\n",
      "            (cbcr0_se_0): SELayer(\n",
      "              (avg_pool): AdaptiveAvgPool1d(output_size=1)\n",
      "              (fc): Sequential(\n",
      "                (0): Linear(in_features=1280, out_features=80, bias=False)\n",
      "                (1): Swish()\n",
      "                (2): Linear(in_features=80, out_features=1280, bias=False)\n",
      "                (3): Sigmoid()\n",
      "              )\n",
      "            )\n",
      "            (cbcr0_0): TemporalConvLayer(\n",
      "              (net): Sequential(\n",
      "                (0): Conv1d(1280, 128, kernel_size=(3,), stride=(1,), padding=(10,), dilation=(5,))\n",
      "                (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (2): Chomp1d()\n",
      "                (3): PReLU(num_parameters=128)\n",
      "              )\n",
      "            )\n",
      "            (cbcr0_se_1): SELayer(\n",
      "              (avg_pool): AdaptiveAvgPool1d(output_size=1)\n",
      "              (fc): Sequential(\n",
      "                (0): Linear(in_features=1280, out_features=80, bias=False)\n",
      "                (1): Swish()\n",
      "                (2): Linear(in_features=80, out_features=1280, bias=False)\n",
      "                (3): Sigmoid()\n",
      "              )\n",
      "            )\n",
      "            (cbcr0_1): TemporalConvLayer(\n",
      "              (net): Sequential(\n",
      "                (0): Conv1d(1280, 128, kernel_size=(5,), stride=(1,), padding=(20,), dilation=(5,))\n",
      "                (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (2): Chomp1d()\n",
      "                (3): PReLU(num_parameters=128)\n",
      "              )\n",
      "            )\n",
      "            (cbcr0_se_2): SELayer(\n",
      "              (avg_pool): AdaptiveAvgPool1d(output_size=1)\n",
      "              (fc): Sequential(\n",
      "                (0): Linear(in_features=1280, out_features=80, bias=False)\n",
      "                (1): Swish()\n",
      "                (2): Linear(in_features=80, out_features=1280, bias=False)\n",
      "                (3): Sigmoid()\n",
      "              )\n",
      "            )\n",
      "            (cbcr0_2): TemporalConvLayer(\n",
      "              (net): Sequential(\n",
      "                (0): Conv1d(1280, 128, kernel_size=(7,), stride=(1,), padding=(30,), dilation=(5,))\n",
      "                (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (2): Chomp1d()\n",
      "                (3): PReLU(num_parameters=128)\n",
      "              )\n",
      "            )\n",
      "            (dropout0): Dropout(p=0.2, inplace=False)\n",
      "            (cbcr1_0): TemporalConvLayer(\n",
      "              (net): Sequential(\n",
      "                (0): Conv1d(384, 128, kernel_size=(3,), stride=(1,), padding=(10,), dilation=(5,))\n",
      "                (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (2): Chomp1d()\n",
      "                (3): PReLU(num_parameters=128)\n",
      "              )\n",
      "            )\n",
      "            (cbcr1_1): TemporalConvLayer(\n",
      "              (net): Sequential(\n",
      "                (0): Conv1d(384, 128, kernel_size=(5,), stride=(1,), padding=(20,), dilation=(5,))\n",
      "                (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (2): Chomp1d()\n",
      "                (3): PReLU(num_parameters=128)\n",
      "              )\n",
      "            )\n",
      "            (cbcr1_2): TemporalConvLayer(\n",
      "              (net): Sequential(\n",
      "                (0): Conv1d(384, 128, kernel_size=(7,), stride=(1,), padding=(30,), dilation=(5,))\n",
      "                (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (2): Chomp1d()\n",
      "                (3): PReLU(num_parameters=128)\n",
      "              )\n",
      "            )\n",
      "            (dropout1): Dropout(p=0.2, inplace=False)\n",
      "            (downsample): Conv1d(1280, 384, kernel_size=(1,), stride=(1,))\n",
      "            (relu_final): PReLU(num_parameters=384)\n",
      "          )\n",
      "        )\n",
      "        (transition3): _Transition(\n",
      "          (conv): Conv1d(1664, 512, kernel_size=(1,), stride=(1,), bias=False)\n",
      "          (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (prelu): PReLU(num_parameters=512)\n",
      "        )\n",
      "        (denseblock4): _DenseBlock(\n",
      "          (denselayer1): _ConvBatchChompRelu(\n",
      "            (cbcr0_se_0): SELayer(\n",
      "              (avg_pool): AdaptiveAvgPool1d(output_size=1)\n",
      "              (fc): Sequential(\n",
      "                (0): Linear(in_features=512, out_features=32, bias=False)\n",
      "                (1): Swish()\n",
      "                (2): Linear(in_features=32, out_features=512, bias=False)\n",
      "                (3): Sigmoid()\n",
      "              )\n",
      "            )\n",
      "            (cbcr0_0): TemporalConvLayer(\n",
      "              (net): Sequential(\n",
      "                (0): Conv1d(512, 128, kernel_size=(3,), stride=(1,), padding=(2,))\n",
      "                (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (2): Chomp1d()\n",
      "                (3): PReLU(num_parameters=128)\n",
      "              )\n",
      "            )\n",
      "            (cbcr0_se_1): SELayer(\n",
      "              (avg_pool): AdaptiveAvgPool1d(output_size=1)\n",
      "              (fc): Sequential(\n",
      "                (0): Linear(in_features=512, out_features=32, bias=False)\n",
      "                (1): Swish()\n",
      "                (2): Linear(in_features=32, out_features=512, bias=False)\n",
      "                (3): Sigmoid()\n",
      "              )\n",
      "            )\n",
      "            (cbcr0_1): TemporalConvLayer(\n",
      "              (net): Sequential(\n",
      "                (0): Conv1d(512, 128, kernel_size=(5,), stride=(1,), padding=(4,))\n",
      "                (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (2): Chomp1d()\n",
      "                (3): PReLU(num_parameters=128)\n",
      "              )\n",
      "            )\n",
      "            (cbcr0_se_2): SELayer(\n",
      "              (avg_pool): AdaptiveAvgPool1d(output_size=1)\n",
      "              (fc): Sequential(\n",
      "                (0): Linear(in_features=512, out_features=32, bias=False)\n",
      "                (1): Swish()\n",
      "                (2): Linear(in_features=32, out_features=512, bias=False)\n",
      "                (3): Sigmoid()\n",
      "              )\n",
      "            )\n",
      "            (cbcr0_2): TemporalConvLayer(\n",
      "              (net): Sequential(\n",
      "                (0): Conv1d(512, 128, kernel_size=(7,), stride=(1,), padding=(6,))\n",
      "                (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (2): Chomp1d()\n",
      "                (3): PReLU(num_parameters=128)\n",
      "              )\n",
      "            )\n",
      "            (dropout0): Dropout(p=0.2, inplace=False)\n",
      "            (cbcr1_0): TemporalConvLayer(\n",
      "              (net): Sequential(\n",
      "                (0): Conv1d(384, 128, kernel_size=(3,), stride=(1,), padding=(2,))\n",
      "                (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (2): Chomp1d()\n",
      "                (3): PReLU(num_parameters=128)\n",
      "              )\n",
      "            )\n",
      "            (cbcr1_1): TemporalConvLayer(\n",
      "              (net): Sequential(\n",
      "                (0): Conv1d(384, 128, kernel_size=(5,), stride=(1,), padding=(4,))\n",
      "                (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (2): Chomp1d()\n",
      "                (3): PReLU(num_parameters=128)\n",
      "              )\n",
      "            )\n",
      "            (cbcr1_2): TemporalConvLayer(\n",
      "              (net): Sequential(\n",
      "                (0): Conv1d(384, 128, kernel_size=(7,), stride=(1,), padding=(6,))\n",
      "                (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (2): Chomp1d()\n",
      "                (3): PReLU(num_parameters=128)\n",
      "              )\n",
      "            )\n",
      "            (dropout1): Dropout(p=0.2, inplace=False)\n",
      "            (downsample): Conv1d(512, 384, kernel_size=(1,), stride=(1,))\n",
      "            (relu_final): PReLU(num_parameters=384)\n",
      "          )\n",
      "          (denselayer2): _ConvBatchChompRelu(\n",
      "            (cbcr0_se_0): SELayer(\n",
      "              (avg_pool): AdaptiveAvgPool1d(output_size=1)\n",
      "              (fc): Sequential(\n",
      "                (0): Linear(in_features=896, out_features=56, bias=False)\n",
      "                (1): Swish()\n",
      "                (2): Linear(in_features=56, out_features=896, bias=False)\n",
      "                (3): Sigmoid()\n",
      "              )\n",
      "            )\n",
      "            (cbcr0_0): TemporalConvLayer(\n",
      "              (net): Sequential(\n",
      "                (0): Conv1d(896, 128, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(2,))\n",
      "                (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (2): Chomp1d()\n",
      "                (3): PReLU(num_parameters=128)\n",
      "              )\n",
      "            )\n",
      "            (cbcr0_se_1): SELayer(\n",
      "              (avg_pool): AdaptiveAvgPool1d(output_size=1)\n",
      "              (fc): Sequential(\n",
      "                (0): Linear(in_features=896, out_features=56, bias=False)\n",
      "                (1): Swish()\n",
      "                (2): Linear(in_features=56, out_features=896, bias=False)\n",
      "                (3): Sigmoid()\n",
      "              )\n",
      "            )\n",
      "            (cbcr0_1): TemporalConvLayer(\n",
      "              (net): Sequential(\n",
      "                (0): Conv1d(896, 128, kernel_size=(5,), stride=(1,), padding=(8,), dilation=(2,))\n",
      "                (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (2): Chomp1d()\n",
      "                (3): PReLU(num_parameters=128)\n",
      "              )\n",
      "            )\n",
      "            (cbcr0_se_2): SELayer(\n",
      "              (avg_pool): AdaptiveAvgPool1d(output_size=1)\n",
      "              (fc): Sequential(\n",
      "                (0): Linear(in_features=896, out_features=56, bias=False)\n",
      "                (1): Swish()\n",
      "                (2): Linear(in_features=56, out_features=896, bias=False)\n",
      "                (3): Sigmoid()\n",
      "              )\n",
      "            )\n",
      "            (cbcr0_2): TemporalConvLayer(\n",
      "              (net): Sequential(\n",
      "                (0): Conv1d(896, 128, kernel_size=(7,), stride=(1,), padding=(12,), dilation=(2,))\n",
      "                (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (2): Chomp1d()\n",
      "                (3): PReLU(num_parameters=128)\n",
      "              )\n",
      "            )\n",
      "            (dropout0): Dropout(p=0.2, inplace=False)\n",
      "            (cbcr1_0): TemporalConvLayer(\n",
      "              (net): Sequential(\n",
      "                (0): Conv1d(384, 128, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(2,))\n",
      "                (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (2): Chomp1d()\n",
      "                (3): PReLU(num_parameters=128)\n",
      "              )\n",
      "            )\n",
      "            (cbcr1_1): TemporalConvLayer(\n",
      "              (net): Sequential(\n",
      "                (0): Conv1d(384, 128, kernel_size=(5,), stride=(1,), padding=(8,), dilation=(2,))\n",
      "                (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (2): Chomp1d()\n",
      "                (3): PReLU(num_parameters=128)\n",
      "              )\n",
      "            )\n",
      "            (cbcr1_2): TemporalConvLayer(\n",
      "              (net): Sequential(\n",
      "                (0): Conv1d(384, 128, kernel_size=(7,), stride=(1,), padding=(12,), dilation=(2,))\n",
      "                (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (2): Chomp1d()\n",
      "                (3): PReLU(num_parameters=128)\n",
      "              )\n",
      "            )\n",
      "            (dropout1): Dropout(p=0.2, inplace=False)\n",
      "            (downsample): Conv1d(896, 384, kernel_size=(1,), stride=(1,))\n",
      "            (relu_final): PReLU(num_parameters=384)\n",
      "          )\n",
      "          (denselayer3): _ConvBatchChompRelu(\n",
      "            (cbcr0_se_0): SELayer(\n",
      "              (avg_pool): AdaptiveAvgPool1d(output_size=1)\n",
      "              (fc): Sequential(\n",
      "                (0): Linear(in_features=1280, out_features=80, bias=False)\n",
      "                (1): Swish()\n",
      "                (2): Linear(in_features=80, out_features=1280, bias=False)\n",
      "                (3): Sigmoid()\n",
      "              )\n",
      "            )\n",
      "            (cbcr0_0): TemporalConvLayer(\n",
      "              (net): Sequential(\n",
      "                (0): Conv1d(1280, 128, kernel_size=(3,), stride=(1,), padding=(10,), dilation=(5,))\n",
      "                (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (2): Chomp1d()\n",
      "                (3): PReLU(num_parameters=128)\n",
      "              )\n",
      "            )\n",
      "            (cbcr0_se_1): SELayer(\n",
      "              (avg_pool): AdaptiveAvgPool1d(output_size=1)\n",
      "              (fc): Sequential(\n",
      "                (0): Linear(in_features=1280, out_features=80, bias=False)\n",
      "                (1): Swish()\n",
      "                (2): Linear(in_features=80, out_features=1280, bias=False)\n",
      "                (3): Sigmoid()\n",
      "              )\n",
      "            )\n",
      "            (cbcr0_1): TemporalConvLayer(\n",
      "              (net): Sequential(\n",
      "                (0): Conv1d(1280, 128, kernel_size=(5,), stride=(1,), padding=(20,), dilation=(5,))\n",
      "                (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (2): Chomp1d()\n",
      "                (3): PReLU(num_parameters=128)\n",
      "              )\n",
      "            )\n",
      "            (cbcr0_se_2): SELayer(\n",
      "              (avg_pool): AdaptiveAvgPool1d(output_size=1)\n",
      "              (fc): Sequential(\n",
      "                (0): Linear(in_features=1280, out_features=80, bias=False)\n",
      "                (1): Swish()\n",
      "                (2): Linear(in_features=80, out_features=1280, bias=False)\n",
      "                (3): Sigmoid()\n",
      "              )\n",
      "            )\n",
      "            (cbcr0_2): TemporalConvLayer(\n",
      "              (net): Sequential(\n",
      "                (0): Conv1d(1280, 128, kernel_size=(7,), stride=(1,), padding=(30,), dilation=(5,))\n",
      "                (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (2): Chomp1d()\n",
      "                (3): PReLU(num_parameters=128)\n",
      "              )\n",
      "            )\n",
      "            (dropout0): Dropout(p=0.2, inplace=False)\n",
      "            (cbcr1_0): TemporalConvLayer(\n",
      "              (net): Sequential(\n",
      "                (0): Conv1d(384, 128, kernel_size=(3,), stride=(1,), padding=(10,), dilation=(5,))\n",
      "                (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (2): Chomp1d()\n",
      "                (3): PReLU(num_parameters=128)\n",
      "              )\n",
      "            )\n",
      "            (cbcr1_1): TemporalConvLayer(\n",
      "              (net): Sequential(\n",
      "                (0): Conv1d(384, 128, kernel_size=(5,), stride=(1,), padding=(20,), dilation=(5,))\n",
      "                (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (2): Chomp1d()\n",
      "                (3): PReLU(num_parameters=128)\n",
      "              )\n",
      "            )\n",
      "            (cbcr1_2): TemporalConvLayer(\n",
      "              (net): Sequential(\n",
      "                (0): Conv1d(384, 128, kernel_size=(7,), stride=(1,), padding=(30,), dilation=(5,))\n",
      "                (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (2): Chomp1d()\n",
      "                (3): PReLU(num_parameters=128)\n",
      "              )\n",
      "            )\n",
      "            (dropout1): Dropout(p=0.2, inplace=False)\n",
      "            (downsample): Conv1d(1280, 384, kernel_size=(1,), stride=(1,))\n",
      "            (relu_final): PReLU(num_parameters=384)\n",
      "          )\n",
      "        )\n",
      "        (norm5): BatchNorm1d(1664, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (tcn_output): Linear(in_features=1664, out_features=237, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Initializing the hyper-parameters\n",
    "densetcn_options = {\n",
    "    'block_config': [3, 3, 3, 3],               # Number of layers in each dense block\n",
    "    'growth_rate_set': [384, 384, 384, 384],    # Growth rate for each block (must be divisible by len(kernel_size_set))\n",
    "    'reduced_size': 512,                        # Reduced size between blocks (must be divisible by len(kernel_size_set))\n",
    "    'kernel_size_set': [3, 5, 7],               # Kernel sizes for multi-scale processing\n",
    "    'dilation_size_set': [1, 2, 5],             # Dilation rates for increasing receptive field\n",
    "    'squeeze_excitation': True,                 # Whether to use SE blocks for channel attention\n",
    "    'dropout': 0.2                              # Dropout rate\n",
    "}\n",
    "initial_lr = 3e-4\n",
    "total_epochs = 80\n",
    "scheduler = CosineScheduler(initial_lr, total_epochs)\n",
    "\n",
    "# Initializing the model\n",
    "model = Lipreading(densetcn_options=densetcn_options, num_classes=len(mapped_classes) + 1).to(device)\n",
    "print(model)\n",
    "\n",
    "# Defining the loss function and optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=initial_lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Training and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the model\n",
    "def train_one_epoch():\n",
    "    running_loss = 0.0\n",
    "    model.train()\n",
    "    ctc_loss = nn.CTCLoss(blank=0, zero_infinity=True)\n",
    "    \n",
    "    for inputs, input_lengths, labels_flat, label_lengths in train_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        input_lengths = input_lengths.to(device)\n",
    "        labels_flat = labels_flat.to(device)\n",
    "        label_lengths = label_lengths.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass - your model needs to output log probabilities\n",
    "        outputs = model(inputs, input_lengths)\n",
    "        outputs = F.log_softmax(outputs, dim=2)\n",
    "        \n",
    "        # Compute CTC loss\n",
    "        loss = ctc_loss(outputs.transpose(0, 1), labels_flat, input_lengths, label_lengths)\n",
    "        \n",
    "        # Backward and optimize\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    return running_loss / len(train_loader)\n",
    "\n",
    "def evaluate_model(return_preds=False):\n",
    "    model.eval()\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    running_loss = 0.0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            running_loss += loss.item()\n",
    "            preds = torch.argmax(outputs, dim=1)\n",
    "            if return_preds:\n",
    "                all_preds.extend(preds.cpu().numpy())\n",
    "                all_labels.extend(labels.cpu().numpy())\n",
    "    return running_loss / len(val_loader), all_preds, all_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model():\n",
    "    # Train and validate\n",
    "    for epoch in range(total_epochs):\n",
    "        train_one_epoch()\n",
    "        scheduler.adjust_lr(optimizer, epoch)\n",
    "        val_loss, _, _ = evaluate_model()\n",
    "        print(f\"Epoch {epoch+1}/{total_epochs}, Val Loss: {val_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 237])\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "Dimension out of range (expected to be in range of [-2, 1], but got 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[10], line 4\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain_model\u001b[39m():\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;66;03m# Train and validate\u001b[39;00m\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(total_epochs):\n\u001b[1;32m----> 4\u001b[0m         \u001b[43mtrain_one_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m         scheduler\u001b[38;5;241m.\u001b[39madjust_lr(optimizer, epoch)\n\u001b[0;32m      6\u001b[0m         val_loss, _, _ \u001b[38;5;241m=\u001b[39m evaluate_model()\n",
      "Cell \u001b[1;32mIn[9], line 24\u001b[0m, in \u001b[0;36mtrain_one_epoch\u001b[1;34m()\u001b[0m\n\u001b[0;32m     22\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model(inputs, input_lengths)\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28mprint\u001b[39m(outputs\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m---> 24\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog_softmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m# Reshape for CTC loss if needed\u001b[39;00m\n\u001b[0;32m     27\u001b[0m outputs \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m)  \u001b[38;5;66;03m# [T, B, C]\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Ramzy\\anaconda3\\envs\\master(pytorch)\\Lib\\site-packages\\torch\\nn\\functional.py:2248\u001b[0m, in \u001b[0;36mlog_softmax\u001b[1;34m(input, dim, _stacklevel, dtype)\u001b[0m\n\u001b[0;32m   2246\u001b[0m     dim \u001b[38;5;241m=\u001b[39m _get_softmax_dim(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlog_softmax\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mdim(), _stacklevel)\n\u001b[0;32m   2247\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 2248\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43minput\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog_softmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdim\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2249\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   2250\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mlog_softmax(dim, dtype\u001b[38;5;241m=\u001b[39mdtype)\n",
      "\u001b[1;31mIndexError\u001b[0m: Dimension out of range (expected to be in range of [-2, 1], but got 2)"
     ]
    }
   ],
   "source": [
    "train_model()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "master(pytorch)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
