{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the libraries for video classification\n",
    "import torch, copy, time, os, cv2\n",
    "from torchvision.models.video.resnet import BasicBlock, Conv3DSimple\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from torchvision import transforms\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Initialize the seed and the device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting the seed for reproducibility\n",
    "seed = 0\n",
    "def reset_seed():\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "# Setting the device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Dataset preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1. Video Dataset Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the video dataset class\n",
    "class VideoDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, video_paths, label_paths, transform=None, frame_count=38):\n",
    "        self.video_paths = video_paths\n",
    "        self.label_paths = label_paths\n",
    "        self.transform = transform\n",
    "        self.frame_count = frame_count\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.video_paths)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        video_path = self.video_paths[index]\n",
    "        label_path = self.label_paths[index]\n",
    "        frames = self.load_frames(video_path=video_path)\n",
    "        label = self.load_label(label_path=label_path)\n",
    "        return frames, label\n",
    "    \n",
    "    def load_frames(self, video_path):\n",
    "        frames = []\n",
    "        video = cv2.VideoCapture(video_path)        \n",
    "        total_frames = int(video.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "        for i in range(total_frames):\n",
    "            video.set(cv2.CAP_PROP_POS_FRAMES, i)\n",
    "            ret, frame = video.read()\n",
    "            if ret:\n",
    "                frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "                frame_pil = Image.fromarray(frame)\n",
    "                frames.append(frame_pil)                \n",
    "        while len(frames) < self.frame_count:\n",
    "            frames.append(frames[-1])   \n",
    "        if self.transform is not None:\n",
    "            frames = [self.transform(frame) for frame in frames] \n",
    "        print(np.array(frames).shape)\n",
    "        frames = torch.stack(frames).permute(1, 0, 2, 3)\n",
    "        return frames\n",
    "    \n",
    "    def load_label(self, label_path):\n",
    "        label = []\n",
    "        diacritics = {\n",
    "            '\\u064B',  # Fathatan\n",
    "            '\\u064C',  # Dammatan\n",
    "            '\\u064D',  # Kasratan\n",
    "            '\\u064E',  # Fatha\n",
    "            '\\u064F',  # Damma\n",
    "            '\\u0650',  # Kasra\n",
    "            '\\u0651',  # Shadda\n",
    "            '\\u0652',  # Sukun\n",
    "            '\\u06E2',  # Small High meem\n",
    "        }\n",
    "        a = pd.read_csv(label_path)\n",
    "        for i in a.word:\n",
    "            for char in i:\n",
    "                if char not in diacritics:\n",
    "                    label.append(char)\n",
    "                else:\n",
    "                    label[-1] += char\n",
    "        return label\n",
    "# Defining the video transform\n",
    "transforms = transforms.Compose([\n",
    "    transforms.Resize((112, 112)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=0.449, std=0.226),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2. Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(38, 1, 112, 112)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 38, 112, 112])"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "videos_dir = \"D:/_hazem/Graduation Project/Arabic-Lib-Reading/Dataset/Video\"\n",
    "labels_dir = \"D:/_hazem/Graduation Project/Arabic-Lib-Reading/Dataset/Csv (with Diacritics)\"\n",
    "videos, labels = [], []\n",
    "file_names = [i[:-4] for i in os.listdir(videos_dir)]\n",
    "for file_name in file_names:\n",
    "    videos.append(os.path.join(videos_dir, file_name + \".mp4\"))\n",
    "    labels.append(os.path.join(labels_dir, file_name + \".csv\"))\n",
    "\n",
    "\n",
    "vid_data = VideoDataset(video_paths=videos, label_paths=labels, transform=transforms)\n",
    "\n",
    "frames, label = vid_data.__getitem__(0)\n",
    "frames.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3. Split the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into training, validation, test sets\n",
    "X_temp, X_test, y_temp, y_test = train_test_split(videos, labels, test_size=0.2, random_state=seed, stratify=labels)\n",
    "kfold = StratifiedKFold(n_splits=3, shuffle=True, random_state=seed)\n",
    "folds = list(kfold.split(np.zeros(len(X_temp)), y_temp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4. DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the video dataloaders (train, validation, test)\n",
    "def get_dataloader(fold, frame_count=16):\n",
    "    train_indices, val_indices = folds[fold]\n",
    "    temp_dataset = VideoDataset(X_temp, y_temp, transform=transforms, frame_count=frame_count)\n",
    "    test_dataset = VideoDataset(X_test, y_test, transform=transforms, frame_count=frame_count)\n",
    "    train_loader = DataLoader(Subset(temp_dataset, train_indices), batch_size=8, shuffle=True, pin_memory=True)\n",
    "    val_loader = DataLoader(Subset(temp_dataset, val_indices), batch_size=8, shuffle=False, pin_memory=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False, pin_memory=True)\n",
    "    return train_loader, val_loader, test_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Training and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the model\n",
    "def train_one_epoch(model, train_loader, optimizer):\n",
    "    model.train()\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "def evaluate_model(model, val_loader, return_preds=False):\n",
    "    model.eval()\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    running_loss = 0.0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            running_loss += loss.item()\n",
    "            preds = torch.argmax(outputs, dim=1)\n",
    "            if return_preds:\n",
    "                all_preds.extend(preds.cpu().numpy())\n",
    "                all_labels.extend(labels.cpu().numpy())\n",
    "    return running_loss / len(val_loader), all_preds, all_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Parallel Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.1. Optimizing the learning rate and training and evaluating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(lr, train_loader, val_loader, model_main):\n",
    "    losses = []\n",
    "    for lr_transfer, lr_tune in lr:\n",
    "        model = copy.deepcopy(model_main)\n",
    "        # Initialize model, optimizer, and loss function\n",
    "        optimizer = optim.Adam(model.parameters(), lr=lr_transfer)\n",
    "        best_val_loss = float('inf')\n",
    "\n",
    "        # Train and validate\n",
    "        for _ in range(15):\n",
    "            train_one_epoch(model, train_loader, optimizer)\n",
    "            val_loss, _, _ = evaluate_model(model, val_loader)\n",
    "            # Early stopping check\n",
    "            if val_loss < best_val_loss:\n",
    "                best_val_loss = val_loss\n",
    "                torch.save(model.state_dict(), \"best_model.pth\")\n",
    "            \n",
    "        model.load_state_dict(torch.load(\"best_model.pth\", weights_only=True))\n",
    "\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = True\n",
    "\n",
    "        optimizer = optim.Adam(model.parameters(), lr=lr_tune)\n",
    "        best_val_loss = float('inf')\n",
    "\n",
    "        for _ in range(5):\n",
    "            train_one_epoch(model, train_loader, optimizer)\n",
    "            val_loss, _, _ = evaluate_model(model, val_loader)\n",
    "            # Early stopping check\n",
    "            if val_loss < best_val_loss:\n",
    "                best_val_loss = val_loss\n",
    "\n",
    "        losses.append(best_val_loss)\n",
    "        print(f\"lr_transfer = {lr_transfer:.10f}, lr_tune: {lr_tune:.10f}, val_loss = {best_val_loss:.4f}\")\n",
    "    time.sleep(0.5)\n",
    "    return np.array(losses)\n",
    "\n",
    "def train_model(model, lr, train_loader, val_loader):\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr[0])\n",
    "    best_val_loss = float('inf')\n",
    "\n",
    "    # Train and validate\n",
    "    for _ in range(60):\n",
    "        train_one_epoch(model, train_loader, optimizer)\n",
    "        val_loss, _, _ = evaluate_model(model, val_loader)\n",
    "        # Early stopping check\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            torch.save(model.state_dict(), \"best_model.pth\")\n",
    "            \n",
    "    model.load_state_dict(torch.load(\"best_model.pth\", weights_only=True))\n",
    "\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = True\n",
    "\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr[1])\n",
    "    best_val_loss = float('inf')\n",
    "\n",
    "    # Train and validate\n",
    "    for _ in range(60):\n",
    "        train_one_epoch(model, train_loader, optimizer)\n",
    "        val_loss, _, _ = evaluate_model(model, val_loader)\n",
    "        # Early stopping check\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            torch.save(model.state_dict(), \"best_model.pth\")\n",
    "            \n",
    "    model.load_state_dict(torch.load(\"best_model.pth\", weights_only=True))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "master(pytorch)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
