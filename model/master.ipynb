{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the libraries for video classification\n",
    "import torch, os, cv2\n",
    "from torchvision.models.video.resnet import BasicBlock, Conv3DSimple\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torchvision import transforms\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from lipreading.model import Lipreading\n",
    "from lipreading.optim_utils import CosineScheduler\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Initialize the seed and the device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting the seed for reproducibility\n",
    "seed = 0\n",
    "def reset_seed():\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "# Setting the device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Dataset preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1. List of Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ٱ': 1, 'يْ': 2, 'يّْ': 3, 'يِّ': 4, 'يُّ': 5, 'يَّ': 6, 'يٌّ': 7, 'يِ': 8, 'يُ': 9, 'يَ': 10, 'يٌ': 11, 'ي': 12, 'ى': 13, 'وْ': 14, 'وِّ': 15, 'وُّ': 16, 'وَّ': 17, 'وِ': 18, 'وُ': 19, 'وَ': 20, 'وً': 21, 'و': 22, 'هْ': 23, 'هُّ': 24, 'هِ': 25, 'هُ': 26, 'هَ': 27, 'نۢ': 28, 'نْ': 29, 'نِّ': 30, 'نُّ': 31, 'نَّ': 32, 'نِ': 33, 'نُ': 34, 'نَ': 35, 'ن': 36, 'مْ': 37, 'مّْ': 38, 'مِّ': 39, 'مُّ': 40, 'مَّ': 41, 'مِ': 42, 'مُ': 43, 'مَ': 44, 'مٍ': 45, 'مٌ': 46, 'مً': 47, 'لْ': 48, 'لّْ': 49, 'لِّ': 50, 'لُّ': 51, 'لَّ': 52, 'لِ': 53, 'لُ': 54, 'لَ': 55, 'لٍ': 56, 'لٌ': 57, 'لً': 58, 'ل': 59, 'كْ': 60, 'كِّ': 61, 'كَّ': 62, 'كِ': 63, 'كُ': 64, 'كَ': 65, 'ك': 66, 'قْ': 67, 'قَّ': 68, 'قِ': 69, 'قُ': 70, 'قَ': 71, 'قٍ': 72, 'قً': 73, 'ق': 74, 'فْ': 75, 'فِّ': 76, 'فَّ': 77, 'فِ': 78, 'فُ': 79, 'فَ': 80, 'غْ': 81, 'غِ': 82, 'غَ': 83, 'عْ': 84, 'عَّ': 85, 'عِ': 86, 'عُ': 87, 'عَ': 88, 'عٍ': 89, 'ظْ': 90, 'ظِّ': 91, 'ظَّ': 92, 'ظِ': 93, 'ظُ': 94, 'ظَ': 95, 'طْ': 96, 'طِّ': 97, 'طَّ': 98, 'طِ': 99, 'طُ': 100, 'طَ': 101, 'ط': 102, 'ضْ': 103, 'ضِّ': 104, 'ضُّ': 105, 'ضَّ': 106, 'ضِ': 107, 'ضُ': 108, 'ضَ': 109, 'ضً': 110, 'صْ': 111, 'صّْ': 112, 'صِّ': 113, 'صُّ': 114, 'صَّ': 115, 'صِ': 116, 'صُ': 117, 'صَ': 118, 'صٍ': 119, 'صً': 120, 'شْ': 121, 'شِّ': 122, 'شُّ': 123, 'شَّ': 124, 'شِ': 125, 'شُ': 126, 'شَ': 127, 'ش': 128, 'سْ': 129, 'سّْ': 130, 'سِّ': 131, 'سُّ': 132, 'سَّ': 133, 'سِ': 134, 'سُ': 135, 'سَ': 136, 'سٍ': 137, 'زْ': 138, 'زَّ': 139, 'زِ': 140, 'زُ': 141, 'زَ': 142, 'رْ': 143, 'رِّ': 144, 'رُّ': 145, 'رَّ': 146, 'رِ': 147, 'رُ': 148, 'رَ': 149, 'رٍ': 150, 'رٌ': 151, 'رً': 152, 'ذْ': 153, 'ذَّ': 154, 'ذِ': 155, 'ذُ': 156, 'ذَ': 157, 'دْ': 158, 'دِّ': 159, 'دُّ': 160, 'دَّ': 161, 'دًّ': 162, 'دِ': 163, 'دُ': 164, 'دَ': 165, 'دٍ': 166, 'دٌ': 167, 'دً': 168, 'خْ': 169, 'خِ': 170, 'خُ': 171, 'خَ': 172, 'حْ': 173, 'حَّ': 174, 'حِ': 175, 'حُ': 176, 'حَ': 177, 'ح': 178, 'جْ': 179, 'جِّ': 180, 'جُّ': 181, 'جَّ': 182, 'جِ': 183, 'جُ': 184, 'جَ': 185, 'ثْ': 186, 'ثِّ': 187, 'ثُّ': 188, 'ثَّ': 189, 'ثِ': 190, 'ثُ': 191, 'ثَ': 192, 'تْ': 193, 'تِّ': 194, 'تُّ': 195, 'تَّ': 196, 'تِ': 197, 'تُ': 198, 'تَ': 199, 'تٍ': 200, 'تٌ': 201, 'ةْ': 202, 'ةِ': 203, 'ةُ': 204, 'ةَ': 205, 'ةٍ': 206, 'ةٌ': 207, 'ةً': 208, 'ة': 209, 'بْ': 210, 'بِّ': 211, 'بَّ': 212, 'بِ': 213, 'بُ': 214, 'بَ': 215, 'بٍ': 216, 'بً': 217, 'ب': 218, 'ا': 219, 'ئْ': 220, 'ئِ': 221, 'ئَ': 222, 'ئً': 223, 'إِ': 224, 'إ': 225, 'ؤْ': 226, 'ؤُ': 227, 'ؤَ': 228, 'ؤ': 229, 'أْ': 230, 'أُ': 231, 'أَ': 232, 'آ': 233, 'ءْ': 234, 'ءِ': 235, 'ءَ': 236, 'ءً': 237}\n"
     ]
    }
   ],
   "source": [
    "def extract_label(file):\n",
    "    label = []\n",
    "    diacritics = {\n",
    "        '\\u064B',  # Fathatan\n",
    "        '\\u064C',  # Dammatan\n",
    "        '\\u064D',  # Kasratan\n",
    "        '\\u064E',  # Fatha\n",
    "        '\\u064F',  # Damma\n",
    "        '\\u0650',  # Kasra\n",
    "        '\\u0651',  # Shadda\n",
    "        '\\u0652',  # Sukun\n",
    "        '\\u06E2',  # Small High meem\n",
    "    }\n",
    "\n",
    "    sentence = pd.read_csv(file)\n",
    "    for word in sentence.word:\n",
    "        for char in word:\n",
    "            if char not in diacritics:\n",
    "                label.append(char)\n",
    "            else:\n",
    "                label[-1] += char\n",
    "\n",
    "    return label\n",
    "\n",
    "classes = set()\n",
    "for i in os.listdir('Dataset/Csv (with Diacritics)'):\n",
    "    file = 'Dataset/Csv (with Diacritics)/' + i\n",
    "    label = extract_label(file)\n",
    "    classes.update(label)\n",
    "\n",
    "mapped_classes = {}\n",
    "for i, c in enumerate(sorted(classes, reverse=True), 1):\n",
    "    mapped_classes[c] = i\n",
    "\n",
    "print(mapped_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2. Video Dataset Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the video dataset class\n",
    "class VideoDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, video_paths, label_paths, transform=None, frame_count=38):\n",
    "        self.video_paths = video_paths\n",
    "        self.label_paths = label_paths\n",
    "        self.transform = transform\n",
    "        self.frame_count = frame_count\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.video_paths)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        video_path = self.video_paths[index]\n",
    "        label_path = self.label_paths[index]\n",
    "        frames = self.load_frames(video_path=video_path)\n",
    "        label = list(map(lambda x: mapped_classes[x], extract_label(label_path)))\n",
    "        return frames, label\n",
    "    \n",
    "    def load_frames(self, video_path):\n",
    "        frames = []\n",
    "        video = cv2.VideoCapture(video_path)\n",
    "        total_frames = int(video.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "        for i in range(total_frames):\n",
    "            video.set(cv2.CAP_PROP_POS_FRAMES, i)\n",
    "            ret, frame = video.read()\n",
    "            if ret:\n",
    "                frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "                frame_pil = Image.fromarray(frame)\n",
    "                frames.append(frame_pil)\n",
    "\n",
    "        while len(frames) < self.frame_count:\n",
    "            frames.append(frames[-1])\n",
    "\n",
    "        if self.transform is not None:\n",
    "            frames = [self.transform(frame) for frame in frames]\n",
    "        frames = torch.stack(frames).permute(1, 0, 2, 3)\n",
    "\n",
    "        return frames\n",
    "\n",
    "# Defining the video transform\n",
    "transforms = transforms.Compose([\n",
    "    transforms.Resize((128, 128)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=0.449, std=0.226),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2. Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "videos_dir = \"Dataset/Video\"\n",
    "labels_dir = \"Dataset/Csv (with Diacritics)\"\n",
    "videos, labels = [], []\n",
    "file_names = [file_name[:-4] for file_name in os.listdir(videos_dir)]\n",
    "for file_name in file_names:\n",
    "    videos.append(os.path.join(videos_dir, file_name + \".mp4\"))\n",
    "    labels.append(os.path.join(labels_dir, file_name + \".csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3. Split the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into training, validation, test sets\n",
    "X_temp, X_test, y_temp, y_test = train_test_split(videos, labels, test_size=0.10, random_state=seed)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_temp, y_temp, test_size=0.11, random_state=seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4. DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 325,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def pad_packed_collate(batch):\n",
    "    \"\"\"Pads data and labels with different lengths in the same batch\n",
    "    \"\"\"\n",
    "    data_tuple, label_tuple = zip(*batch)\n",
    "\n",
    "    # Stack video frames\n",
    "    if len(data_tuple) > 0:\n",
    "        data = torch.stack(data_tuple)\n",
    "    else:\n",
    "        data = torch.empty(0)\n",
    "\n",
    "    # Process labels - need to handle multiple sequences in a batch\n",
    "    if len(label_tuple) > 0:\n",
    "        # Convert each label sequence to a tensor\n",
    "        label_tensors = []\n",
    "        for label_seq in label_tuple:\n",
    "            label_tensors.append(torch.tensor(label_seq, dtype=torch.long))\n",
    "        \n",
    "        # Pad sequences to the same length\n",
    "        labels = pad_sequence(label_tensors, batch_first=True, padding_value=0)\n",
    "    else:\n",
    "        labels = torch.empty(0)\n",
    "    \n",
    "    return data, labels\n",
    "\n",
    "# Defining the video dataloaders (train, validation, test)\n",
    "train_dataset = VideoDataset(X_train, y_train, transform=transforms)\n",
    "val_dataset = VideoDataset(X_val, y_val, transform=transforms)\n",
    "test_dataset = VideoDataset(X_test, y_test, transform=transforms)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, pin_memory=True, collate_fn=pad_packed_collate)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, pin_memory=True, collate_fn=pad_packed_collate)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, pin_memory=True, collate_fn=pad_packed_collate)\n",
    "\n",
    "mx = 0\n",
    "for data, labels in train_loader:\n",
    "    mx = max(mx, labels.size(1))\n",
    "\n",
    "for data, labels in val_loader:\n",
    "    mx = max(mx, labels.size(1))\n",
    "\n",
    "for data, labels in test_loader:\n",
    "    mx = max(mx, labels.size(1))\n",
    "\n",
    "mx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lipreading(\n",
      "  (trunk): ResNet(\n",
      "    (layer1): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): PReLU(num_parameters=64)\n",
      "        (relu2): PReLU(num_parameters=64)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): PReLU(num_parameters=64)\n",
      "        (relu2): PReLU(num_parameters=64)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (layer2): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): PReLU(num_parameters=128)\n",
      "        (relu2): PReLU(num_parameters=128)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): PReLU(num_parameters=128)\n",
      "        (relu2): PReLU(num_parameters=128)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (layer3): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): PReLU(num_parameters=256)\n",
      "        (relu2): PReLU(num_parameters=256)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): PReLU(num_parameters=256)\n",
      "        (relu2): PReLU(num_parameters=256)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (layer4): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): PReLU(num_parameters=512)\n",
      "        (relu2): PReLU(num_parameters=512)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): PReLU(num_parameters=512)\n",
      "        (relu2): PReLU(num_parameters=512)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "  )\n",
      "  (frontend3D): Sequential(\n",
      "    (0): Conv3d(1, 64, kernel_size=(5, 7, 7), stride=(1, 2, 2), padding=(2, 3, 3), bias=False)\n",
      "    (1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): PReLU(num_parameters=64)\n",
      "    (3): MaxPool3d(kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (tcn): DenseTCN(\n",
      "    (tcn_trunk): DenseTemporalConvNet(\n",
      "      (features): Sequential(\n",
      "        (transition0): _Transition(\n",
      "          (conv): Conv1d(512, 512, kernel_size=(1,), stride=(1,), bias=False)\n",
      "          (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (prelu): PReLU(num_parameters=512)\n",
      "        )\n",
      "        (denseblock1): _DenseBlock(\n",
      "          (denselayer1): _ConvBatchChompRelu(\n",
      "            (cbcr0_se_0): SELayer(\n",
      "              (avg_pool): AdaptiveAvgPool1d(output_size=1)\n",
      "              (fc): Sequential(\n",
      "                (0): Linear(in_features=512, out_features=32, bias=False)\n",
      "                (1): Swish()\n",
      "                (2): Linear(in_features=32, out_features=512, bias=False)\n",
      "                (3): Sigmoid()\n",
      "              )\n",
      "            )\n",
      "            (cbcr0_0): TemporalConvLayer(\n",
      "              (net): Sequential(\n",
      "                (0): Conv1d(512, 128, kernel_size=(3,), stride=(1,), padding=(2,))\n",
      "                (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (2): Chomp1d()\n",
      "                (3): PReLU(num_parameters=128)\n",
      "              )\n",
      "            )\n",
      "            (cbcr0_se_1): SELayer(\n",
      "              (avg_pool): AdaptiveAvgPool1d(output_size=1)\n",
      "              (fc): Sequential(\n",
      "                (0): Linear(in_features=512, out_features=32, bias=False)\n",
      "                (1): Swish()\n",
      "                (2): Linear(in_features=32, out_features=512, bias=False)\n",
      "                (3): Sigmoid()\n",
      "              )\n",
      "            )\n",
      "            (cbcr0_1): TemporalConvLayer(\n",
      "              (net): Sequential(\n",
      "                (0): Conv1d(512, 128, kernel_size=(5,), stride=(1,), padding=(4,))\n",
      "                (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (2): Chomp1d()\n",
      "                (3): PReLU(num_parameters=128)\n",
      "              )\n",
      "            )\n",
      "            (cbcr0_se_2): SELayer(\n",
      "              (avg_pool): AdaptiveAvgPool1d(output_size=1)\n",
      "              (fc): Sequential(\n",
      "                (0): Linear(in_features=512, out_features=32, bias=False)\n",
      "                (1): Swish()\n",
      "                (2): Linear(in_features=32, out_features=512, bias=False)\n",
      "                (3): Sigmoid()\n",
      "              )\n",
      "            )\n",
      "            (cbcr0_2): TemporalConvLayer(\n",
      "              (net): Sequential(\n",
      "                (0): Conv1d(512, 128, kernel_size=(7,), stride=(1,), padding=(6,))\n",
      "                (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (2): Chomp1d()\n",
      "                (3): PReLU(num_parameters=128)\n",
      "              )\n",
      "            )\n",
      "            (dropout0): Dropout(p=0.2, inplace=False)\n",
      "            (cbcr1_0): TemporalConvLayer(\n",
      "              (net): Sequential(\n",
      "                (0): Conv1d(384, 128, kernel_size=(3,), stride=(1,), padding=(2,))\n",
      "                (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (2): Chomp1d()\n",
      "                (3): PReLU(num_parameters=128)\n",
      "              )\n",
      "            )\n",
      "            (cbcr1_1): TemporalConvLayer(\n",
      "              (net): Sequential(\n",
      "                (0): Conv1d(384, 128, kernel_size=(5,), stride=(1,), padding=(4,))\n",
      "                (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (2): Chomp1d()\n",
      "                (3): PReLU(num_parameters=128)\n",
      "              )\n",
      "            )\n",
      "            (cbcr1_2): TemporalConvLayer(\n",
      "              (net): Sequential(\n",
      "                (0): Conv1d(384, 128, kernel_size=(7,), stride=(1,), padding=(6,))\n",
      "                (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (2): Chomp1d()\n",
      "                (3): PReLU(num_parameters=128)\n",
      "              )\n",
      "            )\n",
      "            (dropout1): Dropout(p=0.2, inplace=False)\n",
      "            (downsample): Conv1d(512, 384, kernel_size=(1,), stride=(1,))\n",
      "            (relu_final): PReLU(num_parameters=384)\n",
      "          )\n",
      "          (denselayer2): _ConvBatchChompRelu(\n",
      "            (cbcr0_se_0): SELayer(\n",
      "              (avg_pool): AdaptiveAvgPool1d(output_size=1)\n",
      "              (fc): Sequential(\n",
      "                (0): Linear(in_features=896, out_features=56, bias=False)\n",
      "                (1): Swish()\n",
      "                (2): Linear(in_features=56, out_features=896, bias=False)\n",
      "                (3): Sigmoid()\n",
      "              )\n",
      "            )\n",
      "            (cbcr0_0): TemporalConvLayer(\n",
      "              (net): Sequential(\n",
      "                (0): Conv1d(896, 128, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(2,))\n",
      "                (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (2): Chomp1d()\n",
      "                (3): PReLU(num_parameters=128)\n",
      "              )\n",
      "            )\n",
      "            (cbcr0_se_1): SELayer(\n",
      "              (avg_pool): AdaptiveAvgPool1d(output_size=1)\n",
      "              (fc): Sequential(\n",
      "                (0): Linear(in_features=896, out_features=56, bias=False)\n",
      "                (1): Swish()\n",
      "                (2): Linear(in_features=56, out_features=896, bias=False)\n",
      "                (3): Sigmoid()\n",
      "              )\n",
      "            )\n",
      "            (cbcr0_1): TemporalConvLayer(\n",
      "              (net): Sequential(\n",
      "                (0): Conv1d(896, 128, kernel_size=(5,), stride=(1,), padding=(8,), dilation=(2,))\n",
      "                (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (2): Chomp1d()\n",
      "                (3): PReLU(num_parameters=128)\n",
      "              )\n",
      "            )\n",
      "            (cbcr0_se_2): SELayer(\n",
      "              (avg_pool): AdaptiveAvgPool1d(output_size=1)\n",
      "              (fc): Sequential(\n",
      "                (0): Linear(in_features=896, out_features=56, bias=False)\n",
      "                (1): Swish()\n",
      "                (2): Linear(in_features=56, out_features=896, bias=False)\n",
      "                (3): Sigmoid()\n",
      "              )\n",
      "            )\n",
      "            (cbcr0_2): TemporalConvLayer(\n",
      "              (net): Sequential(\n",
      "                (0): Conv1d(896, 128, kernel_size=(7,), stride=(1,), padding=(12,), dilation=(2,))\n",
      "                (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (2): Chomp1d()\n",
      "                (3): PReLU(num_parameters=128)\n",
      "              )\n",
      "            )\n",
      "            (dropout0): Dropout(p=0.2, inplace=False)\n",
      "            (cbcr1_0): TemporalConvLayer(\n",
      "              (net): Sequential(\n",
      "                (0): Conv1d(384, 128, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(2,))\n",
      "                (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (2): Chomp1d()\n",
      "                (3): PReLU(num_parameters=128)\n",
      "              )\n",
      "            )\n",
      "            (cbcr1_1): TemporalConvLayer(\n",
      "              (net): Sequential(\n",
      "                (0): Conv1d(384, 128, kernel_size=(5,), stride=(1,), padding=(8,), dilation=(2,))\n",
      "                (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (2): Chomp1d()\n",
      "                (3): PReLU(num_parameters=128)\n",
      "              )\n",
      "            )\n",
      "            (cbcr1_2): TemporalConvLayer(\n",
      "              (net): Sequential(\n",
      "                (0): Conv1d(384, 128, kernel_size=(7,), stride=(1,), padding=(12,), dilation=(2,))\n",
      "                (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (2): Chomp1d()\n",
      "                (3): PReLU(num_parameters=128)\n",
      "              )\n",
      "            )\n",
      "            (dropout1): Dropout(p=0.2, inplace=False)\n",
      "            (downsample): Conv1d(896, 384, kernel_size=(1,), stride=(1,))\n",
      "            (relu_final): PReLU(num_parameters=384)\n",
      "          )\n",
      "          (denselayer3): _ConvBatchChompRelu(\n",
      "            (cbcr0_se_0): SELayer(\n",
      "              (avg_pool): AdaptiveAvgPool1d(output_size=1)\n",
      "              (fc): Sequential(\n",
      "                (0): Linear(in_features=1280, out_features=80, bias=False)\n",
      "                (1): Swish()\n",
      "                (2): Linear(in_features=80, out_features=1280, bias=False)\n",
      "                (3): Sigmoid()\n",
      "              )\n",
      "            )\n",
      "            (cbcr0_0): TemporalConvLayer(\n",
      "              (net): Sequential(\n",
      "                (0): Conv1d(1280, 128, kernel_size=(3,), stride=(1,), padding=(10,), dilation=(5,))\n",
      "                (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (2): Chomp1d()\n",
      "                (3): PReLU(num_parameters=128)\n",
      "              )\n",
      "            )\n",
      "            (cbcr0_se_1): SELayer(\n",
      "              (avg_pool): AdaptiveAvgPool1d(output_size=1)\n",
      "              (fc): Sequential(\n",
      "                (0): Linear(in_features=1280, out_features=80, bias=False)\n",
      "                (1): Swish()\n",
      "                (2): Linear(in_features=80, out_features=1280, bias=False)\n",
      "                (3): Sigmoid()\n",
      "              )\n",
      "            )\n",
      "            (cbcr0_1): TemporalConvLayer(\n",
      "              (net): Sequential(\n",
      "                (0): Conv1d(1280, 128, kernel_size=(5,), stride=(1,), padding=(20,), dilation=(5,))\n",
      "                (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (2): Chomp1d()\n",
      "                (3): PReLU(num_parameters=128)\n",
      "              )\n",
      "            )\n",
      "            (cbcr0_se_2): SELayer(\n",
      "              (avg_pool): AdaptiveAvgPool1d(output_size=1)\n",
      "              (fc): Sequential(\n",
      "                (0): Linear(in_features=1280, out_features=80, bias=False)\n",
      "                (1): Swish()\n",
      "                (2): Linear(in_features=80, out_features=1280, bias=False)\n",
      "                (3): Sigmoid()\n",
      "              )\n",
      "            )\n",
      "            (cbcr0_2): TemporalConvLayer(\n",
      "              (net): Sequential(\n",
      "                (0): Conv1d(1280, 128, kernel_size=(7,), stride=(1,), padding=(30,), dilation=(5,))\n",
      "                (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (2): Chomp1d()\n",
      "                (3): PReLU(num_parameters=128)\n",
      "              )\n",
      "            )\n",
      "            (dropout0): Dropout(p=0.2, inplace=False)\n",
      "            (cbcr1_0): TemporalConvLayer(\n",
      "              (net): Sequential(\n",
      "                (0): Conv1d(384, 128, kernel_size=(3,), stride=(1,), padding=(10,), dilation=(5,))\n",
      "                (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (2): Chomp1d()\n",
      "                (3): PReLU(num_parameters=128)\n",
      "              )\n",
      "            )\n",
      "            (cbcr1_1): TemporalConvLayer(\n",
      "              (net): Sequential(\n",
      "                (0): Conv1d(384, 128, kernel_size=(5,), stride=(1,), padding=(20,), dilation=(5,))\n",
      "                (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (2): Chomp1d()\n",
      "                (3): PReLU(num_parameters=128)\n",
      "              )\n",
      "            )\n",
      "            (cbcr1_2): TemporalConvLayer(\n",
      "              (net): Sequential(\n",
      "                (0): Conv1d(384, 128, kernel_size=(7,), stride=(1,), padding=(30,), dilation=(5,))\n",
      "                (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (2): Chomp1d()\n",
      "                (3): PReLU(num_parameters=128)\n",
      "              )\n",
      "            )\n",
      "            (dropout1): Dropout(p=0.2, inplace=False)\n",
      "            (downsample): Conv1d(1280, 384, kernel_size=(1,), stride=(1,))\n",
      "            (relu_final): PReLU(num_parameters=384)\n",
      "          )\n",
      "        )\n",
      "        (transition1): _Transition(\n",
      "          (conv): Conv1d(1664, 512, kernel_size=(1,), stride=(1,), bias=False)\n",
      "          (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (prelu): PReLU(num_parameters=512)\n",
      "        )\n",
      "        (denseblock2): _DenseBlock(\n",
      "          (denselayer1): _ConvBatchChompRelu(\n",
      "            (cbcr0_se_0): SELayer(\n",
      "              (avg_pool): AdaptiveAvgPool1d(output_size=1)\n",
      "              (fc): Sequential(\n",
      "                (0): Linear(in_features=512, out_features=32, bias=False)\n",
      "                (1): Swish()\n",
      "                (2): Linear(in_features=32, out_features=512, bias=False)\n",
      "                (3): Sigmoid()\n",
      "              )\n",
      "            )\n",
      "            (cbcr0_0): TemporalConvLayer(\n",
      "              (net): Sequential(\n",
      "                (0): Conv1d(512, 128, kernel_size=(3,), stride=(1,), padding=(2,))\n",
      "                (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (2): Chomp1d()\n",
      "                (3): PReLU(num_parameters=128)\n",
      "              )\n",
      "            )\n",
      "            (cbcr0_se_1): SELayer(\n",
      "              (avg_pool): AdaptiveAvgPool1d(output_size=1)\n",
      "              (fc): Sequential(\n",
      "                (0): Linear(in_features=512, out_features=32, bias=False)\n",
      "                (1): Swish()\n",
      "                (2): Linear(in_features=32, out_features=512, bias=False)\n",
      "                (3): Sigmoid()\n",
      "              )\n",
      "            )\n",
      "            (cbcr0_1): TemporalConvLayer(\n",
      "              (net): Sequential(\n",
      "                (0): Conv1d(512, 128, kernel_size=(5,), stride=(1,), padding=(4,))\n",
      "                (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (2): Chomp1d()\n",
      "                (3): PReLU(num_parameters=128)\n",
      "              )\n",
      "            )\n",
      "            (cbcr0_se_2): SELayer(\n",
      "              (avg_pool): AdaptiveAvgPool1d(output_size=1)\n",
      "              (fc): Sequential(\n",
      "                (0): Linear(in_features=512, out_features=32, bias=False)\n",
      "                (1): Swish()\n",
      "                (2): Linear(in_features=32, out_features=512, bias=False)\n",
      "                (3): Sigmoid()\n",
      "              )\n",
      "            )\n",
      "            (cbcr0_2): TemporalConvLayer(\n",
      "              (net): Sequential(\n",
      "                (0): Conv1d(512, 128, kernel_size=(7,), stride=(1,), padding=(6,))\n",
      "                (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (2): Chomp1d()\n",
      "                (3): PReLU(num_parameters=128)\n",
      "              )\n",
      "            )\n",
      "            (dropout0): Dropout(p=0.2, inplace=False)\n",
      "            (cbcr1_0): TemporalConvLayer(\n",
      "              (net): Sequential(\n",
      "                (0): Conv1d(384, 128, kernel_size=(3,), stride=(1,), padding=(2,))\n",
      "                (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (2): Chomp1d()\n",
      "                (3): PReLU(num_parameters=128)\n",
      "              )\n",
      "            )\n",
      "            (cbcr1_1): TemporalConvLayer(\n",
      "              (net): Sequential(\n",
      "                (0): Conv1d(384, 128, kernel_size=(5,), stride=(1,), padding=(4,))\n",
      "                (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (2): Chomp1d()\n",
      "                (3): PReLU(num_parameters=128)\n",
      "              )\n",
      "            )\n",
      "            (cbcr1_2): TemporalConvLayer(\n",
      "              (net): Sequential(\n",
      "                (0): Conv1d(384, 128, kernel_size=(7,), stride=(1,), padding=(6,))\n",
      "                (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (2): Chomp1d()\n",
      "                (3): PReLU(num_parameters=128)\n",
      "              )\n",
      "            )\n",
      "            (dropout1): Dropout(p=0.2, inplace=False)\n",
      "            (downsample): Conv1d(512, 384, kernel_size=(1,), stride=(1,))\n",
      "            (relu_final): PReLU(num_parameters=384)\n",
      "          )\n",
      "          (denselayer2): _ConvBatchChompRelu(\n",
      "            (cbcr0_se_0): SELayer(\n",
      "              (avg_pool): AdaptiveAvgPool1d(output_size=1)\n",
      "              (fc): Sequential(\n",
      "                (0): Linear(in_features=896, out_features=56, bias=False)\n",
      "                (1): Swish()\n",
      "                (2): Linear(in_features=56, out_features=896, bias=False)\n",
      "                (3): Sigmoid()\n",
      "              )\n",
      "            )\n",
      "            (cbcr0_0): TemporalConvLayer(\n",
      "              (net): Sequential(\n",
      "                (0): Conv1d(896, 128, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(2,))\n",
      "                (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (2): Chomp1d()\n",
      "                (3): PReLU(num_parameters=128)\n",
      "              )\n",
      "            )\n",
      "            (cbcr0_se_1): SELayer(\n",
      "              (avg_pool): AdaptiveAvgPool1d(output_size=1)\n",
      "              (fc): Sequential(\n",
      "                (0): Linear(in_features=896, out_features=56, bias=False)\n",
      "                (1): Swish()\n",
      "                (2): Linear(in_features=56, out_features=896, bias=False)\n",
      "                (3): Sigmoid()\n",
      "              )\n",
      "            )\n",
      "            (cbcr0_1): TemporalConvLayer(\n",
      "              (net): Sequential(\n",
      "                (0): Conv1d(896, 128, kernel_size=(5,), stride=(1,), padding=(8,), dilation=(2,))\n",
      "                (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (2): Chomp1d()\n",
      "                (3): PReLU(num_parameters=128)\n",
      "              )\n",
      "            )\n",
      "            (cbcr0_se_2): SELayer(\n",
      "              (avg_pool): AdaptiveAvgPool1d(output_size=1)\n",
      "              (fc): Sequential(\n",
      "                (0): Linear(in_features=896, out_features=56, bias=False)\n",
      "                (1): Swish()\n",
      "                (2): Linear(in_features=56, out_features=896, bias=False)\n",
      "                (3): Sigmoid()\n",
      "              )\n",
      "            )\n",
      "            (cbcr0_2): TemporalConvLayer(\n",
      "              (net): Sequential(\n",
      "                (0): Conv1d(896, 128, kernel_size=(7,), stride=(1,), padding=(12,), dilation=(2,))\n",
      "                (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (2): Chomp1d()\n",
      "                (3): PReLU(num_parameters=128)\n",
      "              )\n",
      "            )\n",
      "            (dropout0): Dropout(p=0.2, inplace=False)\n",
      "            (cbcr1_0): TemporalConvLayer(\n",
      "              (net): Sequential(\n",
      "                (0): Conv1d(384, 128, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(2,))\n",
      "                (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (2): Chomp1d()\n",
      "                (3): PReLU(num_parameters=128)\n",
      "              )\n",
      "            )\n",
      "            (cbcr1_1): TemporalConvLayer(\n",
      "              (net): Sequential(\n",
      "                (0): Conv1d(384, 128, kernel_size=(5,), stride=(1,), padding=(8,), dilation=(2,))\n",
      "                (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (2): Chomp1d()\n",
      "                (3): PReLU(num_parameters=128)\n",
      "              )\n",
      "            )\n",
      "            (cbcr1_2): TemporalConvLayer(\n",
      "              (net): Sequential(\n",
      "                (0): Conv1d(384, 128, kernel_size=(7,), stride=(1,), padding=(12,), dilation=(2,))\n",
      "                (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (2): Chomp1d()\n",
      "                (3): PReLU(num_parameters=128)\n",
      "              )\n",
      "            )\n",
      "            (dropout1): Dropout(p=0.2, inplace=False)\n",
      "            (downsample): Conv1d(896, 384, kernel_size=(1,), stride=(1,))\n",
      "            (relu_final): PReLU(num_parameters=384)\n",
      "          )\n",
      "          (denselayer3): _ConvBatchChompRelu(\n",
      "            (cbcr0_se_0): SELayer(\n",
      "              (avg_pool): AdaptiveAvgPool1d(output_size=1)\n",
      "              (fc): Sequential(\n",
      "                (0): Linear(in_features=1280, out_features=80, bias=False)\n",
      "                (1): Swish()\n",
      "                (2): Linear(in_features=80, out_features=1280, bias=False)\n",
      "                (3): Sigmoid()\n",
      "              )\n",
      "            )\n",
      "            (cbcr0_0): TemporalConvLayer(\n",
      "              (net): Sequential(\n",
      "                (0): Conv1d(1280, 128, kernel_size=(3,), stride=(1,), padding=(10,), dilation=(5,))\n",
      "                (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (2): Chomp1d()\n",
      "                (3): PReLU(num_parameters=128)\n",
      "              )\n",
      "            )\n",
      "            (cbcr0_se_1): SELayer(\n",
      "              (avg_pool): AdaptiveAvgPool1d(output_size=1)\n",
      "              (fc): Sequential(\n",
      "                (0): Linear(in_features=1280, out_features=80, bias=False)\n",
      "                (1): Swish()\n",
      "                (2): Linear(in_features=80, out_features=1280, bias=False)\n",
      "                (3): Sigmoid()\n",
      "              )\n",
      "            )\n",
      "            (cbcr0_1): TemporalConvLayer(\n",
      "              (net): Sequential(\n",
      "                (0): Conv1d(1280, 128, kernel_size=(5,), stride=(1,), padding=(20,), dilation=(5,))\n",
      "                (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (2): Chomp1d()\n",
      "                (3): PReLU(num_parameters=128)\n",
      "              )\n",
      "            )\n",
      "            (cbcr0_se_2): SELayer(\n",
      "              (avg_pool): AdaptiveAvgPool1d(output_size=1)\n",
      "              (fc): Sequential(\n",
      "                (0): Linear(in_features=1280, out_features=80, bias=False)\n",
      "                (1): Swish()\n",
      "                (2): Linear(in_features=80, out_features=1280, bias=False)\n",
      "                (3): Sigmoid()\n",
      "              )\n",
      "            )\n",
      "            (cbcr0_2): TemporalConvLayer(\n",
      "              (net): Sequential(\n",
      "                (0): Conv1d(1280, 128, kernel_size=(7,), stride=(1,), padding=(30,), dilation=(5,))\n",
      "                (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (2): Chomp1d()\n",
      "                (3): PReLU(num_parameters=128)\n",
      "              )\n",
      "            )\n",
      "            (dropout0): Dropout(p=0.2, inplace=False)\n",
      "            (cbcr1_0): TemporalConvLayer(\n",
      "              (net): Sequential(\n",
      "                (0): Conv1d(384, 128, kernel_size=(3,), stride=(1,), padding=(10,), dilation=(5,))\n",
      "                (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (2): Chomp1d()\n",
      "                (3): PReLU(num_parameters=128)\n",
      "              )\n",
      "            )\n",
      "            (cbcr1_1): TemporalConvLayer(\n",
      "              (net): Sequential(\n",
      "                (0): Conv1d(384, 128, kernel_size=(5,), stride=(1,), padding=(20,), dilation=(5,))\n",
      "                (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (2): Chomp1d()\n",
      "                (3): PReLU(num_parameters=128)\n",
      "              )\n",
      "            )\n",
      "            (cbcr1_2): TemporalConvLayer(\n",
      "              (net): Sequential(\n",
      "                (0): Conv1d(384, 128, kernel_size=(7,), stride=(1,), padding=(30,), dilation=(5,))\n",
      "                (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (2): Chomp1d()\n",
      "                (3): PReLU(num_parameters=128)\n",
      "              )\n",
      "            )\n",
      "            (dropout1): Dropout(p=0.2, inplace=False)\n",
      "            (downsample): Conv1d(1280, 384, kernel_size=(1,), stride=(1,))\n",
      "            (relu_final): PReLU(num_parameters=384)\n",
      "          )\n",
      "        )\n",
      "        (transition2): _Transition(\n",
      "          (conv): Conv1d(1664, 512, kernel_size=(1,), stride=(1,), bias=False)\n",
      "          (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (prelu): PReLU(num_parameters=512)\n",
      "        )\n",
      "        (denseblock3): _DenseBlock(\n",
      "          (denselayer1): _ConvBatchChompRelu(\n",
      "            (cbcr0_se_0): SELayer(\n",
      "              (avg_pool): AdaptiveAvgPool1d(output_size=1)\n",
      "              (fc): Sequential(\n",
      "                (0): Linear(in_features=512, out_features=32, bias=False)\n",
      "                (1): Swish()\n",
      "                (2): Linear(in_features=32, out_features=512, bias=False)\n",
      "                (3): Sigmoid()\n",
      "              )\n",
      "            )\n",
      "            (cbcr0_0): TemporalConvLayer(\n",
      "              (net): Sequential(\n",
      "                (0): Conv1d(512, 128, kernel_size=(3,), stride=(1,), padding=(2,))\n",
      "                (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (2): Chomp1d()\n",
      "                (3): PReLU(num_parameters=128)\n",
      "              )\n",
      "            )\n",
      "            (cbcr0_se_1): SELayer(\n",
      "              (avg_pool): AdaptiveAvgPool1d(output_size=1)\n",
      "              (fc): Sequential(\n",
      "                (0): Linear(in_features=512, out_features=32, bias=False)\n",
      "                (1): Swish()\n",
      "                (2): Linear(in_features=32, out_features=512, bias=False)\n",
      "                (3): Sigmoid()\n",
      "              )\n",
      "            )\n",
      "            (cbcr0_1): TemporalConvLayer(\n",
      "              (net): Sequential(\n",
      "                (0): Conv1d(512, 128, kernel_size=(5,), stride=(1,), padding=(4,))\n",
      "                (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (2): Chomp1d()\n",
      "                (3): PReLU(num_parameters=128)\n",
      "              )\n",
      "            )\n",
      "            (cbcr0_se_2): SELayer(\n",
      "              (avg_pool): AdaptiveAvgPool1d(output_size=1)\n",
      "              (fc): Sequential(\n",
      "                (0): Linear(in_features=512, out_features=32, bias=False)\n",
      "                (1): Swish()\n",
      "                (2): Linear(in_features=32, out_features=512, bias=False)\n",
      "                (3): Sigmoid()\n",
      "              )\n",
      "            )\n",
      "            (cbcr0_2): TemporalConvLayer(\n",
      "              (net): Sequential(\n",
      "                (0): Conv1d(512, 128, kernel_size=(7,), stride=(1,), padding=(6,))\n",
      "                (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (2): Chomp1d()\n",
      "                (3): PReLU(num_parameters=128)\n",
      "              )\n",
      "            )\n",
      "            (dropout0): Dropout(p=0.2, inplace=False)\n",
      "            (cbcr1_0): TemporalConvLayer(\n",
      "              (net): Sequential(\n",
      "                (0): Conv1d(384, 128, kernel_size=(3,), stride=(1,), padding=(2,))\n",
      "                (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (2): Chomp1d()\n",
      "                (3): PReLU(num_parameters=128)\n",
      "              )\n",
      "            )\n",
      "            (cbcr1_1): TemporalConvLayer(\n",
      "              (net): Sequential(\n",
      "                (0): Conv1d(384, 128, kernel_size=(5,), stride=(1,), padding=(4,))\n",
      "                (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (2): Chomp1d()\n",
      "                (3): PReLU(num_parameters=128)\n",
      "              )\n",
      "            )\n",
      "            (cbcr1_2): TemporalConvLayer(\n",
      "              (net): Sequential(\n",
      "                (0): Conv1d(384, 128, kernel_size=(7,), stride=(1,), padding=(6,))\n",
      "                (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (2): Chomp1d()\n",
      "                (3): PReLU(num_parameters=128)\n",
      "              )\n",
      "            )\n",
      "            (dropout1): Dropout(p=0.2, inplace=False)\n",
      "            (downsample): Conv1d(512, 384, kernel_size=(1,), stride=(1,))\n",
      "            (relu_final): PReLU(num_parameters=384)\n",
      "          )\n",
      "          (denselayer2): _ConvBatchChompRelu(\n",
      "            (cbcr0_se_0): SELayer(\n",
      "              (avg_pool): AdaptiveAvgPool1d(output_size=1)\n",
      "              (fc): Sequential(\n",
      "                (0): Linear(in_features=896, out_features=56, bias=False)\n",
      "                (1): Swish()\n",
      "                (2): Linear(in_features=56, out_features=896, bias=False)\n",
      "                (3): Sigmoid()\n",
      "              )\n",
      "            )\n",
      "            (cbcr0_0): TemporalConvLayer(\n",
      "              (net): Sequential(\n",
      "                (0): Conv1d(896, 128, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(2,))\n",
      "                (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (2): Chomp1d()\n",
      "                (3): PReLU(num_parameters=128)\n",
      "              )\n",
      "            )\n",
      "            (cbcr0_se_1): SELayer(\n",
      "              (avg_pool): AdaptiveAvgPool1d(output_size=1)\n",
      "              (fc): Sequential(\n",
      "                (0): Linear(in_features=896, out_features=56, bias=False)\n",
      "                (1): Swish()\n",
      "                (2): Linear(in_features=56, out_features=896, bias=False)\n",
      "                (3): Sigmoid()\n",
      "              )\n",
      "            )\n",
      "            (cbcr0_1): TemporalConvLayer(\n",
      "              (net): Sequential(\n",
      "                (0): Conv1d(896, 128, kernel_size=(5,), stride=(1,), padding=(8,), dilation=(2,))\n",
      "                (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (2): Chomp1d()\n",
      "                (3): PReLU(num_parameters=128)\n",
      "              )\n",
      "            )\n",
      "            (cbcr0_se_2): SELayer(\n",
      "              (avg_pool): AdaptiveAvgPool1d(output_size=1)\n",
      "              (fc): Sequential(\n",
      "                (0): Linear(in_features=896, out_features=56, bias=False)\n",
      "                (1): Swish()\n",
      "                (2): Linear(in_features=56, out_features=896, bias=False)\n",
      "                (3): Sigmoid()\n",
      "              )\n",
      "            )\n",
      "            (cbcr0_2): TemporalConvLayer(\n",
      "              (net): Sequential(\n",
      "                (0): Conv1d(896, 128, kernel_size=(7,), stride=(1,), padding=(12,), dilation=(2,))\n",
      "                (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (2): Chomp1d()\n",
      "                (3): PReLU(num_parameters=128)\n",
      "              )\n",
      "            )\n",
      "            (dropout0): Dropout(p=0.2, inplace=False)\n",
      "            (cbcr1_0): TemporalConvLayer(\n",
      "              (net): Sequential(\n",
      "                (0): Conv1d(384, 128, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(2,))\n",
      "                (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (2): Chomp1d()\n",
      "                (3): PReLU(num_parameters=128)\n",
      "              )\n",
      "            )\n",
      "            (cbcr1_1): TemporalConvLayer(\n",
      "              (net): Sequential(\n",
      "                (0): Conv1d(384, 128, kernel_size=(5,), stride=(1,), padding=(8,), dilation=(2,))\n",
      "                (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (2): Chomp1d()\n",
      "                (3): PReLU(num_parameters=128)\n",
      "              )\n",
      "            )\n",
      "            (cbcr1_2): TemporalConvLayer(\n",
      "              (net): Sequential(\n",
      "                (0): Conv1d(384, 128, kernel_size=(7,), stride=(1,), padding=(12,), dilation=(2,))\n",
      "                (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (2): Chomp1d()\n",
      "                (3): PReLU(num_parameters=128)\n",
      "              )\n",
      "            )\n",
      "            (dropout1): Dropout(p=0.2, inplace=False)\n",
      "            (downsample): Conv1d(896, 384, kernel_size=(1,), stride=(1,))\n",
      "            (relu_final): PReLU(num_parameters=384)\n",
      "          )\n",
      "          (denselayer3): _ConvBatchChompRelu(\n",
      "            (cbcr0_se_0): SELayer(\n",
      "              (avg_pool): AdaptiveAvgPool1d(output_size=1)\n",
      "              (fc): Sequential(\n",
      "                (0): Linear(in_features=1280, out_features=80, bias=False)\n",
      "                (1): Swish()\n",
      "                (2): Linear(in_features=80, out_features=1280, bias=False)\n",
      "                (3): Sigmoid()\n",
      "              )\n",
      "            )\n",
      "            (cbcr0_0): TemporalConvLayer(\n",
      "              (net): Sequential(\n",
      "                (0): Conv1d(1280, 128, kernel_size=(3,), stride=(1,), padding=(10,), dilation=(5,))\n",
      "                (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (2): Chomp1d()\n",
      "                (3): PReLU(num_parameters=128)\n",
      "              )\n",
      "            )\n",
      "            (cbcr0_se_1): SELayer(\n",
      "              (avg_pool): AdaptiveAvgPool1d(output_size=1)\n",
      "              (fc): Sequential(\n",
      "                (0): Linear(in_features=1280, out_features=80, bias=False)\n",
      "                (1): Swish()\n",
      "                (2): Linear(in_features=80, out_features=1280, bias=False)\n",
      "                (3): Sigmoid()\n",
      "              )\n",
      "            )\n",
      "            (cbcr0_1): TemporalConvLayer(\n",
      "              (net): Sequential(\n",
      "                (0): Conv1d(1280, 128, kernel_size=(5,), stride=(1,), padding=(20,), dilation=(5,))\n",
      "                (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (2): Chomp1d()\n",
      "                (3): PReLU(num_parameters=128)\n",
      "              )\n",
      "            )\n",
      "            (cbcr0_se_2): SELayer(\n",
      "              (avg_pool): AdaptiveAvgPool1d(output_size=1)\n",
      "              (fc): Sequential(\n",
      "                (0): Linear(in_features=1280, out_features=80, bias=False)\n",
      "                (1): Swish()\n",
      "                (2): Linear(in_features=80, out_features=1280, bias=False)\n",
      "                (3): Sigmoid()\n",
      "              )\n",
      "            )\n",
      "            (cbcr0_2): TemporalConvLayer(\n",
      "              (net): Sequential(\n",
      "                (0): Conv1d(1280, 128, kernel_size=(7,), stride=(1,), padding=(30,), dilation=(5,))\n",
      "                (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (2): Chomp1d()\n",
      "                (3): PReLU(num_parameters=128)\n",
      "              )\n",
      "            )\n",
      "            (dropout0): Dropout(p=0.2, inplace=False)\n",
      "            (cbcr1_0): TemporalConvLayer(\n",
      "              (net): Sequential(\n",
      "                (0): Conv1d(384, 128, kernel_size=(3,), stride=(1,), padding=(10,), dilation=(5,))\n",
      "                (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (2): Chomp1d()\n",
      "                (3): PReLU(num_parameters=128)\n",
      "              )\n",
      "            )\n",
      "            (cbcr1_1): TemporalConvLayer(\n",
      "              (net): Sequential(\n",
      "                (0): Conv1d(384, 128, kernel_size=(5,), stride=(1,), padding=(20,), dilation=(5,))\n",
      "                (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (2): Chomp1d()\n",
      "                (3): PReLU(num_parameters=128)\n",
      "              )\n",
      "            )\n",
      "            (cbcr1_2): TemporalConvLayer(\n",
      "              (net): Sequential(\n",
      "                (0): Conv1d(384, 128, kernel_size=(7,), stride=(1,), padding=(30,), dilation=(5,))\n",
      "                (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (2): Chomp1d()\n",
      "                (3): PReLU(num_parameters=128)\n",
      "              )\n",
      "            )\n",
      "            (dropout1): Dropout(p=0.2, inplace=False)\n",
      "            (downsample): Conv1d(1280, 384, kernel_size=(1,), stride=(1,))\n",
      "            (relu_final): PReLU(num_parameters=384)\n",
      "          )\n",
      "        )\n",
      "        (transition3): _Transition(\n",
      "          (conv): Conv1d(1664, 512, kernel_size=(1,), stride=(1,), bias=False)\n",
      "          (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (prelu): PReLU(num_parameters=512)\n",
      "        )\n",
      "        (denseblock4): _DenseBlock(\n",
      "          (denselayer1): _ConvBatchChompRelu(\n",
      "            (cbcr0_se_0): SELayer(\n",
      "              (avg_pool): AdaptiveAvgPool1d(output_size=1)\n",
      "              (fc): Sequential(\n",
      "                (0): Linear(in_features=512, out_features=32, bias=False)\n",
      "                (1): Swish()\n",
      "                (2): Linear(in_features=32, out_features=512, bias=False)\n",
      "                (3): Sigmoid()\n",
      "              )\n",
      "            )\n",
      "            (cbcr0_0): TemporalConvLayer(\n",
      "              (net): Sequential(\n",
      "                (0): Conv1d(512, 128, kernel_size=(3,), stride=(1,), padding=(2,))\n",
      "                (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (2): Chomp1d()\n",
      "                (3): PReLU(num_parameters=128)\n",
      "              )\n",
      "            )\n",
      "            (cbcr0_se_1): SELayer(\n",
      "              (avg_pool): AdaptiveAvgPool1d(output_size=1)\n",
      "              (fc): Sequential(\n",
      "                (0): Linear(in_features=512, out_features=32, bias=False)\n",
      "                (1): Swish()\n",
      "                (2): Linear(in_features=32, out_features=512, bias=False)\n",
      "                (3): Sigmoid()\n",
      "              )\n",
      "            )\n",
      "            (cbcr0_1): TemporalConvLayer(\n",
      "              (net): Sequential(\n",
      "                (0): Conv1d(512, 128, kernel_size=(5,), stride=(1,), padding=(4,))\n",
      "                (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (2): Chomp1d()\n",
      "                (3): PReLU(num_parameters=128)\n",
      "              )\n",
      "            )\n",
      "            (cbcr0_se_2): SELayer(\n",
      "              (avg_pool): AdaptiveAvgPool1d(output_size=1)\n",
      "              (fc): Sequential(\n",
      "                (0): Linear(in_features=512, out_features=32, bias=False)\n",
      "                (1): Swish()\n",
      "                (2): Linear(in_features=32, out_features=512, bias=False)\n",
      "                (3): Sigmoid()\n",
      "              )\n",
      "            )\n",
      "            (cbcr0_2): TemporalConvLayer(\n",
      "              (net): Sequential(\n",
      "                (0): Conv1d(512, 128, kernel_size=(7,), stride=(1,), padding=(6,))\n",
      "                (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (2): Chomp1d()\n",
      "                (3): PReLU(num_parameters=128)\n",
      "              )\n",
      "            )\n",
      "            (dropout0): Dropout(p=0.2, inplace=False)\n",
      "            (cbcr1_0): TemporalConvLayer(\n",
      "              (net): Sequential(\n",
      "                (0): Conv1d(384, 128, kernel_size=(3,), stride=(1,), padding=(2,))\n",
      "                (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (2): Chomp1d()\n",
      "                (3): PReLU(num_parameters=128)\n",
      "              )\n",
      "            )\n",
      "            (cbcr1_1): TemporalConvLayer(\n",
      "              (net): Sequential(\n",
      "                (0): Conv1d(384, 128, kernel_size=(5,), stride=(1,), padding=(4,))\n",
      "                (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (2): Chomp1d()\n",
      "                (3): PReLU(num_parameters=128)\n",
      "              )\n",
      "            )\n",
      "            (cbcr1_2): TemporalConvLayer(\n",
      "              (net): Sequential(\n",
      "                (0): Conv1d(384, 128, kernel_size=(7,), stride=(1,), padding=(6,))\n",
      "                (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (2): Chomp1d()\n",
      "                (3): PReLU(num_parameters=128)\n",
      "              )\n",
      "            )\n",
      "            (dropout1): Dropout(p=0.2, inplace=False)\n",
      "            (downsample): Conv1d(512, 384, kernel_size=(1,), stride=(1,))\n",
      "            (relu_final): PReLU(num_parameters=384)\n",
      "          )\n",
      "          (denselayer2): _ConvBatchChompRelu(\n",
      "            (cbcr0_se_0): SELayer(\n",
      "              (avg_pool): AdaptiveAvgPool1d(output_size=1)\n",
      "              (fc): Sequential(\n",
      "                (0): Linear(in_features=896, out_features=56, bias=False)\n",
      "                (1): Swish()\n",
      "                (2): Linear(in_features=56, out_features=896, bias=False)\n",
      "                (3): Sigmoid()\n",
      "              )\n",
      "            )\n",
      "            (cbcr0_0): TemporalConvLayer(\n",
      "              (net): Sequential(\n",
      "                (0): Conv1d(896, 128, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(2,))\n",
      "                (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (2): Chomp1d()\n",
      "                (3): PReLU(num_parameters=128)\n",
      "              )\n",
      "            )\n",
      "            (cbcr0_se_1): SELayer(\n",
      "              (avg_pool): AdaptiveAvgPool1d(output_size=1)\n",
      "              (fc): Sequential(\n",
      "                (0): Linear(in_features=896, out_features=56, bias=False)\n",
      "                (1): Swish()\n",
      "                (2): Linear(in_features=56, out_features=896, bias=False)\n",
      "                (3): Sigmoid()\n",
      "              )\n",
      "            )\n",
      "            (cbcr0_1): TemporalConvLayer(\n",
      "              (net): Sequential(\n",
      "                (0): Conv1d(896, 128, kernel_size=(5,), stride=(1,), padding=(8,), dilation=(2,))\n",
      "                (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (2): Chomp1d()\n",
      "                (3): PReLU(num_parameters=128)\n",
      "              )\n",
      "            )\n",
      "            (cbcr0_se_2): SELayer(\n",
      "              (avg_pool): AdaptiveAvgPool1d(output_size=1)\n",
      "              (fc): Sequential(\n",
      "                (0): Linear(in_features=896, out_features=56, bias=False)\n",
      "                (1): Swish()\n",
      "                (2): Linear(in_features=56, out_features=896, bias=False)\n",
      "                (3): Sigmoid()\n",
      "              )\n",
      "            )\n",
      "            (cbcr0_2): TemporalConvLayer(\n",
      "              (net): Sequential(\n",
      "                (0): Conv1d(896, 128, kernel_size=(7,), stride=(1,), padding=(12,), dilation=(2,))\n",
      "                (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (2): Chomp1d()\n",
      "                (3): PReLU(num_parameters=128)\n",
      "              )\n",
      "            )\n",
      "            (dropout0): Dropout(p=0.2, inplace=False)\n",
      "            (cbcr1_0): TemporalConvLayer(\n",
      "              (net): Sequential(\n",
      "                (0): Conv1d(384, 128, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(2,))\n",
      "                (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (2): Chomp1d()\n",
      "                (3): PReLU(num_parameters=128)\n",
      "              )\n",
      "            )\n",
      "            (cbcr1_1): TemporalConvLayer(\n",
      "              (net): Sequential(\n",
      "                (0): Conv1d(384, 128, kernel_size=(5,), stride=(1,), padding=(8,), dilation=(2,))\n",
      "                (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (2): Chomp1d()\n",
      "                (3): PReLU(num_parameters=128)\n",
      "              )\n",
      "            )\n",
      "            (cbcr1_2): TemporalConvLayer(\n",
      "              (net): Sequential(\n",
      "                (0): Conv1d(384, 128, kernel_size=(7,), stride=(1,), padding=(12,), dilation=(2,))\n",
      "                (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (2): Chomp1d()\n",
      "                (3): PReLU(num_parameters=128)\n",
      "              )\n",
      "            )\n",
      "            (dropout1): Dropout(p=0.2, inplace=False)\n",
      "            (downsample): Conv1d(896, 384, kernel_size=(1,), stride=(1,))\n",
      "            (relu_final): PReLU(num_parameters=384)\n",
      "          )\n",
      "          (denselayer3): _ConvBatchChompRelu(\n",
      "            (cbcr0_se_0): SELayer(\n",
      "              (avg_pool): AdaptiveAvgPool1d(output_size=1)\n",
      "              (fc): Sequential(\n",
      "                (0): Linear(in_features=1280, out_features=80, bias=False)\n",
      "                (1): Swish()\n",
      "                (2): Linear(in_features=80, out_features=1280, bias=False)\n",
      "                (3): Sigmoid()\n",
      "              )\n",
      "            )\n",
      "            (cbcr0_0): TemporalConvLayer(\n",
      "              (net): Sequential(\n",
      "                (0): Conv1d(1280, 128, kernel_size=(3,), stride=(1,), padding=(10,), dilation=(5,))\n",
      "                (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (2): Chomp1d()\n",
      "                (3): PReLU(num_parameters=128)\n",
      "              )\n",
      "            )\n",
      "            (cbcr0_se_1): SELayer(\n",
      "              (avg_pool): AdaptiveAvgPool1d(output_size=1)\n",
      "              (fc): Sequential(\n",
      "                (0): Linear(in_features=1280, out_features=80, bias=False)\n",
      "                (1): Swish()\n",
      "                (2): Linear(in_features=80, out_features=1280, bias=False)\n",
      "                (3): Sigmoid()\n",
      "              )\n",
      "            )\n",
      "            (cbcr0_1): TemporalConvLayer(\n",
      "              (net): Sequential(\n",
      "                (0): Conv1d(1280, 128, kernel_size=(5,), stride=(1,), padding=(20,), dilation=(5,))\n",
      "                (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (2): Chomp1d()\n",
      "                (3): PReLU(num_parameters=128)\n",
      "              )\n",
      "            )\n",
      "            (cbcr0_se_2): SELayer(\n",
      "              (avg_pool): AdaptiveAvgPool1d(output_size=1)\n",
      "              (fc): Sequential(\n",
      "                (0): Linear(in_features=1280, out_features=80, bias=False)\n",
      "                (1): Swish()\n",
      "                (2): Linear(in_features=80, out_features=1280, bias=False)\n",
      "                (3): Sigmoid()\n",
      "              )\n",
      "            )\n",
      "            (cbcr0_2): TemporalConvLayer(\n",
      "              (net): Sequential(\n",
      "                (0): Conv1d(1280, 128, kernel_size=(7,), stride=(1,), padding=(30,), dilation=(5,))\n",
      "                (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (2): Chomp1d()\n",
      "                (3): PReLU(num_parameters=128)\n",
      "              )\n",
      "            )\n",
      "            (dropout0): Dropout(p=0.2, inplace=False)\n",
      "            (cbcr1_0): TemporalConvLayer(\n",
      "              (net): Sequential(\n",
      "                (0): Conv1d(384, 128, kernel_size=(3,), stride=(1,), padding=(10,), dilation=(5,))\n",
      "                (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (2): Chomp1d()\n",
      "                (3): PReLU(num_parameters=128)\n",
      "              )\n",
      "            )\n",
      "            (cbcr1_1): TemporalConvLayer(\n",
      "              (net): Sequential(\n",
      "                (0): Conv1d(384, 128, kernel_size=(5,), stride=(1,), padding=(20,), dilation=(5,))\n",
      "                (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (2): Chomp1d()\n",
      "                (3): PReLU(num_parameters=128)\n",
      "              )\n",
      "            )\n",
      "            (cbcr1_2): TemporalConvLayer(\n",
      "              (net): Sequential(\n",
      "                (0): Conv1d(384, 128, kernel_size=(7,), stride=(1,), padding=(30,), dilation=(5,))\n",
      "                (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (2): Chomp1d()\n",
      "                (3): PReLU(num_parameters=128)\n",
      "              )\n",
      "            )\n",
      "            (dropout1): Dropout(p=0.2, inplace=False)\n",
      "            (downsample): Conv1d(1280, 384, kernel_size=(1,), stride=(1,))\n",
      "            (relu_final): PReLU(num_parameters=384)\n",
      "          )\n",
      "        )\n",
      "        (norm5): BatchNorm1d(1664, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (tcn_output): Linear(in_features=1664, out_features=500, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Initializing the hyper-parameters\n",
    "densetcn_options = {\n",
    "    'block_config': [3, 3, 3, 3],               # Number of layers in each dense block\n",
    "    'growth_rate_set': [384, 384, 384, 384],    # Growth rate for each block (must be divisible by len(kernel_size_set))\n",
    "    'reduced_size': 512,                        # Reduced size between blocks (must be divisible by len(kernel_size_set))\n",
    "    'kernel_size_set': [3, 5, 7],               # Kernel sizes for multi-scale processing\n",
    "    'dilation_size_set': [1, 2, 5],             # Dilation rates for increasing receptive field\n",
    "    'squeeze_excitation': True,                 # Whether to use SE blocks for channel attention\n",
    "    'dropout': 0.2                              # Dropout rate\n",
    "}\n",
    "initial_lr = 3e-4\n",
    "total_epochs = 80\n",
    "scheduler = CosineScheduler(initial_lr, total_epochs)\n",
    "\n",
    "# Initializing the model\n",
    "model = Lipreading(densetcn_options=densetcn_options).to(device)\n",
    "print(model)\n",
    "\n",
    "# Defining the loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=initial_lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Training and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the model\n",
    "def train_one_epoch():\n",
    "    model.train()\n",
    "    ctc_loss = nn.CTCLoss(blank=0, zero_infinity=True)\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        lengths = torch.full((inputs.size(0),), inputs.size(2), dtype=torch.long).to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs, lengths)\n",
    "        print(outputs.shape, labels.shape)\n",
    "        print(outputs, labels)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "def evaluate_model(return_preds=False):\n",
    "    model.eval()\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    running_loss = 0.0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            running_loss += loss.item()\n",
    "            preds = torch.argmax(outputs, dim=1)\n",
    "            if return_preds:\n",
    "                all_preds.extend(preds.cpu().numpy())\n",
    "                all_labels.extend(labels.cpu().numpy())\n",
    "    return running_loss / len(val_loader), all_preds, all_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model():\n",
    "    # Train and validate\n",
    "    for epoch in range(total_epochs):\n",
    "        train_one_epoch()\n",
    "        scheduler.adjust_lr(optimizer, epoch)\n",
    "        val_loss, _, _ = evaluate_model()\n",
    "        print(f\"Epoch {epoch+1}/{total_epochs}, Val Loss: {val_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 500]) torch.Size([16, 21])\n",
      "tensor([[ 6.1449e-01,  5.9690e-01,  5.1144e-01,  ...,  4.3322e-01,\n",
      "         -8.4315e-01,  9.7986e-01],\n",
      "        [ 1.1649e-01, -2.4263e-01, -2.8991e-01,  ..., -3.7814e-01,\n",
      "          8.5668e-01, -7.2118e-01],\n",
      "        [-6.6158e-01,  1.2242e-01,  2.6624e-01,  ...,  3.0973e-01,\n",
      "         -2.8001e-01,  1.0593e+00],\n",
      "        ...,\n",
      "        [ 4.0884e-01, -6.2515e-01,  6.3304e-01,  ...,  2.5760e-01,\n",
      "         -4.2663e-04,  3.7911e-01],\n",
      "        [ 3.2163e-02,  3.3229e-01, -3.2084e-01,  ...,  1.0061e-01,\n",
      "         -1.4393e-01, -6.1168e-01],\n",
      "        [-5.9941e-02,  7.1031e-02, -2.5896e-01,  ...,  4.5861e-01,\n",
      "          4.2672e-01, -1.1116e-01]], device='cuda:0', grad_fn=<AddmmBackward0>) tensor([[232,  84,  55,  35, 193,   1,  48,  18,  55, 219,  10, 219, 198,   1,\n",
      "          48,  43, 196, 175, 158,   0,   0],\n",
      "        [ 71, 219,  55, 193,  20,  65, 219,  55, 204,   1,  48, 232,  28, 215,\n",
      "         219, 235,   1,  48, 224,  44, 219],\n",
      "        [184,  37,  26,  22, 147,   6, 202, 127,  44, 219,  48,  70, 210, 148,\n",
      "         111,   0,   0,   0,   0,   0,   0],\n",
      "        [ 44,  14,  69,  80,   1,  48, 176,  64,  22,  44, 203,   1,  48,  80,\n",
      "         149,  29, 134,  12,   0,   0,   0],\n",
      "        [ 44,  84,  54,  22,  44, 219, 193,  88,  29,  27, 157, 219,   0,   0,\n",
      "           0,   0,   0,   0,   0,   0,   0],\n",
      "        [ 43,  35,  92,  44, 204,   1,  48, 231,  44,  37,   1,  48,  43, 196,\n",
      "         175, 158,   0,   0,   0,   0,   0],\n",
      "        [ 71, 219,  55,  43, 149, 219, 134,  48,   1,  48, 185, 140,  12, 149,\n",
      "          23,   0,   0,   0,   0,   0,   0],\n",
      "        [183, 162,  88,  29,   1,  48,  44,  84,  54,  22,  44, 219, 193,   0,\n",
      "           0,   0,   0,   0,   0,   0,   0],\n",
      "        [190,   4,  12,  35,  20,  70,  17, 219, 197,   1,  48,  44, 169,  54,\n",
      "          22,  86,   0,   0,   0,   0,   0],\n",
      "        [ 65, 219,  55, 204,   1,  48, 232,  28, 215, 219, 235,   1,  48,  71,\n",
      "         101, 147,   3,   0,   0,   0,   0],\n",
      "        [183,   6, 204,   1,  48, 232,  42,  12, 147,  12,  63,   6,  23, 224,\n",
      "          32,  33,  90,   0,   0,   0,   0],\n",
      "        [ 20,  75, 165,   3,   1,  48, 176,  64,  22,  44,  23,   1,  48,  10,\n",
      "          44,  33,   6,  23,   0,   0,   0],\n",
      "        [ 42,  29, 183,  27, 197,  25, 232, 127, 219, 149,   0,   0,   0,   0,\n",
      "           0,   0,   0,   0,   0,   0,   0],\n",
      "        [ 71, 219,  55,   1,  48,  43, 199, 177, 159, 191, 213, 129,  37,   0,\n",
      "           0,   0,   0,   0,   0,   0,   0],\n",
      "        [215, 219, 234,  42,  29,  71,  35, 219, 203,   1,  48, 185, 140,  12,\n",
      "         149,  23,   0,   0,   0,   0,   0],\n",
      "        [224,  29, 199,  27,  13,   1,  48,  43,  22, 185, 138, 224,  55,  13,\n",
      "           1,  50,  71, 219, 234,   0,   0]], device='cuda:0')\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "0D or 1D target tensor expected, multi-target not supported",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[315], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[314], line 4\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain_model\u001b[39m():\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;66;03m# Train and validate\u001b[39;00m\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(total_epochs):\n\u001b[1;32m----> 4\u001b[0m         \u001b[43mtrain_one_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m         scheduler\u001b[38;5;241m.\u001b[39madjust_lr(optimizer, epoch)\n\u001b[0;32m      6\u001b[0m         val_loss, _, _ \u001b[38;5;241m=\u001b[39m evaluate_model()\n",
      "Cell \u001b[1;32mIn[313], line 12\u001b[0m, in \u001b[0;36mtrain_one_epoch\u001b[1;34m()\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(outputs\u001b[38;5;241m.\u001b[39mshape, labels\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(outputs, labels)\n\u001b[1;32m---> 12\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43mcriterion\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     13\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m     14\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[1;32mc:\\Users\\Ramzy\\anaconda3\\envs\\master(pytorch)\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Ramzy\\anaconda3\\envs\\master(pytorch)\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\Ramzy\\anaconda3\\envs\\master(pytorch)\\Lib\\site-packages\\torch\\nn\\modules\\loss.py:1293\u001b[0m, in \u001b[0;36mCrossEntropyLoss.forward\u001b[1;34m(self, input, target)\u001b[0m\n\u001b[0;32m   1292\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, target: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m-> 1293\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_entropy\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1294\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1295\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1296\u001b[0m \u001b[43m        \u001b[49m\u001b[43mweight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1297\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1298\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreduction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1299\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1300\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Ramzy\\anaconda3\\envs\\master(pytorch)\\Lib\\site-packages\\torch\\nn\\functional.py:3479\u001b[0m, in \u001b[0;36mcross_entropy\u001b[1;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[0;32m   3477\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m size_average \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m reduce \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   3478\u001b[0m     reduction \u001b[38;5;241m=\u001b[39m _Reduction\u001b[38;5;241m.\u001b[39mlegacy_get_string(size_average, reduce)\n\u001b[1;32m-> 3479\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_nn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_entropy_loss\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3480\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3481\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3482\u001b[0m \u001b[43m    \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3483\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_Reduction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_enum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3484\u001b[0m \u001b[43m    \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3485\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3486\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: 0D or 1D target tensor expected, multi-target not supported"
     ]
    }
   ],
   "source": [
    "train_model()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "master(pytorch)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
